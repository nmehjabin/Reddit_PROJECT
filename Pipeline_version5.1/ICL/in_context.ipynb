{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Prep the dataset: copy the labeled dataset, unlabel it and then save 10 examples from the labeled data where label = 1 for passing as few-shot examples and then the rest of the datasets would be unlabled test split."
      ],
      "metadata": {
        "id": "UmKH7WyljL_8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "df = pd.read_csv(\"manual_label_batch1_updated.csv\")\n",
        "\n",
        "print(f\"Original dataset shape: {df.shape}\")\n",
        "print(f\"Columns: {df.columns.tolist()}\")\n",
        "print(f\"\\nLabel distribution:\")\n",
        "print(df['label'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hicS1Y6jjzJ",
        "outputId": "b6079ca7-65ab-4345-9f76-0a0833d332ee"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original dataset shape: (188, 4)\n",
            "Columns: ['id', 'text', 'similarity_score', 'label']\n",
            "\n",
            "Label distribution:\n",
            "label\n",
            "0    139\n",
            "1     49\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Create a copy and save the full labeled dataset as backup\n",
        "print(\"\\nSaving full labeled dataset as backup...\")\n",
        "df_backup = df.copy()\n",
        "df_backup.to_csv('labeled_data_backup.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jFb5C7AjtJ2",
        "outputId": "f53ff69e-4f62-4604-9797-c03bac69450b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Saving full labeled dataset as backup...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Extract 10 examples where label = 1 for few-shot learning\n",
        "print(\"\\nExtracting 10 examples where label = 1 for few-shot prompts\")\n",
        "burnout_examples = df[df['label'] == 1].sample(n=20, random_state=42)\n",
        "fewshot_examples = burnout_examples.copy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61oOSJe0j7jr",
        "outputId": "2efc41a1-19f0-4b8b-ad4c-cb1c8fcbe730"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Extracting 10 examples where label = 1 for few-shot prompts\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save few-shot examples (with labels)\n",
        "fewshot_examples.to_csv('fewshot_examples.csv', index=False)\n",
        "print(f\"Few-shot examples saved: {fewshot_examples.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3zSMuhnj_4n",
        "outputId": "674045b3-93cd-4b31-acc2-1b97e740eaf3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Few-shot examples saved: (20, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Create test set (remaining data after removing few-shot examples)\n",
        "# Get indices of few-shot examples\n",
        "fewshot_indices = burnout_examples.index\n",
        "\n",
        "# Remove few-shot examples from the dataset to create test set\n",
        "test_data = df.drop(fewshot_indices)\n",
        "\n",
        "print(f\"Test set shape: {test_data.shape}\")\n",
        "print(f\"Test set label distribution:\")\n",
        "print(test_data['label'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bUwu10-kP32",
        "outputId": "e01ae04e-fe57-437a-9708-a42bd17f7122"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set shape: (168, 4)\n",
            "Test set label distribution:\n",
            "label\n",
            "0    139\n",
            "1     29\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Save test set WITH labels (for validation later)\n",
        "test_data.to_csv('test_data_with_labels.csv', index=False)\n",
        "print(\"\\nTest data with labels saved: test_data_with_labels.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIlOmiqxkliW",
        "outputId": "b9378f01-106c-454f-949f-05e5d7c628dc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test data with labels saved: test_data_with_labels.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Create and save test set WITHOUT labels (for actual inference)\n",
        "test_data_unlabeled = test_data.drop(columns=['label'])\n",
        "test_data_unlabeled.to_csv('test_data_unlabeled.csv', index=False)\n",
        "print(\"Test data without labels saved: test_data_unlabeled.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lR_UxsUmkwXf",
        "outputId": "2559b7fe-d156-4e69-aa0a-14dab3a988b3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test data without labels saved: test_data_unlabeled.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Original dataset: {df.shape[0]} rows\")\n",
        "print(f\"Few-shot examples (label=1): {fewshot_examples.shape[0]} rows\")\n",
        "print(f\"Test set: {test_data.shape[0]} rows\")\n",
        "print(f\"  - Label 0: {(test_data['label'] == 0).sum()} rows\")\n",
        "print(f\"  - Label 1: {(test_data['label'] == 1).sum()} rows\")\n",
        "print(\"\\nFiles created:\")\n",
        "print(\"  1. labeled_data_backup.csv - Full dataset with labels (backup)\")\n",
        "print(\"  2. fewshot_examples.csv - 10 examples where label=1 (for prompts)\")\n",
        "print(\"  3. test_data_with_labels.csv - Test set WITH labels (for validation)\")\n",
        "print(\"  4. test_data_unlabeled.csv - Test set WITHOUT labels (for inference)\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5SKb04jk2do",
        "outputId": "379cf21a-6a35-44af-ab60-0ae058f73ab8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SUMMARY\n",
            "============================================================\n",
            "Original dataset: 188 rows\n",
            "Few-shot examples (label=1): 20 rows\n",
            "Test set: 168 rows\n",
            "  - Label 0: 139 rows\n",
            "  - Label 1: 29 rows\n",
            "\n",
            "Files created:\n",
            "  1. labeled_data_backup.csv - Full dataset with labels (backup)\n",
            "  2. fewshot_examples.csv - 10 examples where label=1 (for prompts)\n",
            "  3. test_data_with_labels.csv - Test set WITH labels (for validation)\n",
            "  4. test_data_unlabeled.csv - Test set WITHOUT labels (for inference)\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install anthropic"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jq_8A0gzut5",
        "outputId": "380b9a2a-0dc0-41f6-85c4-7e53a6a41e4c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting anthropic\n",
            "  Downloading anthropic-0.79.0-py3-none-any.whl.metadata (28 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from anthropic) (4.12.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from anthropic) (1.9.0)\n",
            "Requirement already satisfied: docstring-parser<1,>=0.15 in /usr/local/lib/python3.12/dist-packages (from anthropic) (0.17.0)\n",
            "Requirement already satisfied: httpx<1,>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from anthropic) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from anthropic) (0.13.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from anthropic) (2.12.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from anthropic) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from anthropic) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->anthropic) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->anthropic) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->anthropic) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.25.0->anthropic) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->anthropic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->anthropic) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->anthropic) (0.4.2)\n",
            "Downloading anthropic-0.79.0-py3-none-any.whl (405 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/405.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m405.9/405.9 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: anthropic\n",
            "Successfully installed anthropic-0.79.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import anthropic\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "# # Access the secret key from Colab secrets\n",
        "# CLAUDE = userdata.get('CLAUDE_API')  # Replace 'CLAUDE' with whatever you named your secret\n",
        "\n",
        "# # Initialize Anthropic client\n",
        "# client = anthropic.Anthropic(api_key=CLAUDE)\n",
        "\n",
        "\n",
        "CLAUDE = userdata.get('CLAUDE_API').strip()  # or whatever you named it\n",
        "print(f\"API key loaded: {CLAUDE[:10]}...\")  # Print first 10 chars to verify\n",
        "\n",
        "# Initialize client\n",
        "client = anthropic.Anthropic(api_key=CLAUDE)\n",
        "\n",
        "# Quick test\n",
        "# message = client.messages.create(\n",
        "#     model=\"claude-sonnet-4-20250514\",\n",
        "#     max_tokens=100,\n",
        "#     messages=[{\"role\": \"user\", \"content\": \"Say hello!\"}]\n",
        "# )\n",
        "# print(message.content[0].text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVfx1D6szzWH",
        "outputId": "0c7a481f-e02b-45ad-d98a-6def020825b3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API key loaded: sk-ant-api...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Model parameters\n",
        "MODEL_SONNET = \"claude-sonnet-4-20250514\"  # Claude Sonnet 4\n",
        "TEMPERATURE = 0\n",
        "MAX_TOKENS = 200"
      ],
      "metadata": {
        "id": "EVb-zdFez3c3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ZERO SHOT Prompting\n",
        "\n",
        "ZERO_SHOT_PROMPT = \"\"\"Title: \"Classification of Work-Related Burnout and Stress in Cybersecurity Professionals\"\n",
        "\n",
        "Definition: In this task, we ask you to classify the input text into two options:\n",
        "\n",
        "1: Work-related burnout/stress: The poster discussed burnout or work-related stress related to their own mental health in the past or present.\n",
        "The context of burnout can be related to work, career, job responsibilities, workplace environment, or professional life in cybersecurity.\n",
        "\n",
        "0: No work-related burnout/stress: Burnout or stress used in a context unrelated to work or mental health. Or work-related burnout/stress\n",
        "in hypothetical situations when the poster is not discussing their own experience in the past and present.\n",
        "\n",
        "Emphasis & Caution: Discussions of hypothetical situations such as fear of burnout or future/imaginary circumstances should NOT be labeled as 1.\n",
        "\n",
        "Things to avoid: All input must be classified into one of the options. If you cannot pick then choose the option with higher probability. The output\n",
        "must be either 1 or 0 but not both.\n",
        "\n",
        "Input: {text}\n",
        "\n",
        "Output:\"\"\"\n",
        "\n",
        "ZERO_SHOT_COT_PROMPT = \"\"\"Title: \"Classification of Work-Related Burnout and Stress in Cybersecurity Professionals\"\n",
        "\n",
        "Definition: In this task, we ask you to classify the input text into two options:\n",
        "\n",
        "1 : Work-related burnout/stress: The poster discussed burnout or work-related stress related to their own mental health in the past or present. The context of burnout can be related to work, career, job responsibilities, workplace environment, or professional life in cybersecurity.\n",
        "0 : No work-related burnout/stress: Burnout or stress used in a context unrelated to work or mental health. Or work-related burnout/stress in hypothetical situations when the poster is not discussing their own experience in the past and present.\n",
        "\n",
        "Emphasis & Caution: Discussions of hypothetical situations such as fear of burnout or future/imaginary circumstances should NOT be labeled as 1.\n",
        "\n",
        "Things to avoid: All input must be classified into one of the options. If you cannot pick then choose the option with higher probability. The output must be either 1 or 0 but not both.\n",
        "\n",
        "Input: {text}\n",
        "\n",
        "Let's think about it step by step.\n",
        "\n",
        "Output:\"\"\""
      ],
      "metadata": {
        "id": "eArT6Zri0Esh"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Helper function for few shot\n",
        "\n",
        "def create_fewshot_examples(fewshot_df, text_column):\n",
        "    \"\"\"Create formatted few-shot examples from the dataframe\"\"\"\n",
        "    examples = []\n",
        "    for idx, row in fewshot_df.iterrows():\n",
        "        label = 1 if row['label'] == 1 else 0\n",
        "        example = f\"Input: {row[text_column]}\\nOutput: {label}\"\n",
        "        examples.append(example)\n",
        "    return \"\\n\\n\".join(examples)\n",
        "\n",
        "def create_fewshot_prompt(fewshot_examples_text, is_cot=False):\n",
        "    \"\"\"Create few-shot prompt template\"\"\"\n",
        "    cot_instruction = \"\\n\\nLet's think about it step by step.\" if is_cot else \"\"\n",
        "\n",
        "    prompt = f\"\"\"Title: \"Classification of Work-Related Burnout and Stress in Cybersecurity Professionals\"\n",
        "\n",
        "Definition: In this task, we ask you to classify the input text into two options:\n",
        "\n",
        "1: Work-related burnout/stress: The poster discussed burnout or work-related stress related to their own mental health in the past or present. The context of burnout can be related to work, career, job responsibilities, workplace environment, or professional life in cybersecurity.\n",
        "\n",
        "0: No work-related burnout/stress: Burnout or stress used in a context unrelated to work or mental health. Or work-related burnout/stress in hypothetical situations when the poster is not discussing their own experience in the past and present.\n",
        "\n",
        "Emphasis & Caution: Discussions of hypothetical situations such as fear of burnout or future/imaginary circumstances should NOT be labeled as 1.\n",
        "\n",
        "Things to avoid: All input must be classified into one of the options. If you cannot pick then choose the option with higher probability. The output must be either 0 or 1 but not both.\n",
        "\n",
        "Here are some examples:\n",
        "\n",
        "{fewshot_examples_text}\n",
        "\n",
        "Now classify the following:\n",
        "\n",
        "Input: {{text}}{cot_instruction}\n",
        "\n",
        "Output:\"\"\"\n",
        "\n",
        "    return prompt\n",
        "\n"
      ],
      "metadata": {
        "id": "KAVDjIAz1ASV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def truncate_text(text, max_chars=10000):\n",
        "    \"\"\"Truncate text to fit context window\"\"\"\n",
        "    if len(text) > max_chars:\n",
        "        return text[:max_chars] + \"...\"\n",
        "    return text"
      ],
      "metadata": {
        "id": "seOBXBsa1mG-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def call_claude_api(prompt, model=MODEL_SONNET):\n",
        "    \"\"\"Call Claude API with error handling and retry logic\"\"\"\n",
        "    max_retries = 3\n",
        "    retry_delay = 2\n",
        "\n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            message = client.messages.create(\n",
        "                model=model,\n",
        "                max_tokens=MAX_TOKENS,\n",
        "                temperature=TEMPERATURE,\n",
        "                messages=[\n",
        "                    {\"role\": \"user\", \"content\": prompt}\n",
        "                ]\n",
        "            )\n",
        "            return message.content[0].text.strip()\n",
        "\n",
        "        except anthropic.RateLimitError as e:\n",
        "            print(f\"Rate limit hit on attempt {attempt + 1}: {str(e)}\")\n",
        "            if attempt < max_retries - 1:\n",
        "                time.sleep(retry_delay)\n",
        "                retry_delay *= 2\n",
        "            else:\n",
        "                return \"ERROR: RATE_LIMIT\"\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Attempt {attempt + 1} failed: {str(e)}\")\n",
        "            if attempt < max_retries - 1:\n",
        "                time.sleep(retry_delay)\n",
        "                retry_delay *= 2\n",
        "            else:\n",
        "                return f\"ERROR: {str(e)}\"\n",
        "\n",
        "    return \"ERROR\""
      ],
      "metadata": {
        "id": "2uNC246C1py1"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_output(output):\n",
        "    \"\"\"Parse model output to extract 0 or 1\"\"\"\n",
        "    output = output.strip()\n",
        "\n",
        "    # Look for 0 or 1 in the output\n",
        "    if \"1\" in output:\n",
        "        return 1\n",
        "    elif \"0\" in output:\n",
        "        return 0\n",
        "    else:\n",
        "        return 0  # Parse error"
      ],
      "metadata": {
        "id": "jQl6Vc-W10Iw"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_dataset(test_df, text_column, prompt_template, model, approach_name):\n",
        "    \"\"\"Classify entire dataset and return results\"\"\"\n",
        "    results = []\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Running {approach_name} with {model}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    for idx, row in tqdm(test_df.iterrows(), total=len(test_df), desc=\"Classifying\"):\n",
        "        text = truncate_text(str(row[text_column]))\n",
        "        prompt = prompt_template.format(text=text)\n",
        "\n",
        "        # Call API\n",
        "        raw_output = call_claude_api(prompt, model)\n",
        "\n",
        "        # Parse output\n",
        "        predicted_label = parse_output(raw_output)\n",
        "\n",
        "        results.append({\n",
        "            'index': idx,\n",
        "            'text': row[text_column],\n",
        "            'raw_output': raw_output,\n",
        "            'predicted_label': predicted_label,\n",
        "            'approach': approach_name,\n",
        "            'model': model\n",
        "        })\n",
        "\n",
        "        # Rate limiting - delay between requests\n",
        "        time.sleep(1)  # Claude API rate limits can be strict\n",
        "\n",
        "    return pd.DataFrame(results)"
      ],
      "metadata": {
        "id": "Lle5rKLW15Kf"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # Configuration - CHANGE THESE TO MATCH COLUMN NAMES\n",
        "    TEXT_COLUMN = 'text'\n",
        "    LABEL_COLUMN = 'label'\n",
        "\n",
        "    # Load data\n",
        "    print(\"Loading data...\")\n",
        "    fewshot_df = pd.read_csv('fewshot_examples.csv')\n",
        "    test_df = pd.read_csv('test_data_unlabeled.csv')\n",
        "    test_labels = pd.read_csv('test_data_with_labels.csv')\n",
        "\n",
        "    print(f\"Few-shot examples: {len(fewshot_df)}\")\n",
        "    print(f\"Test samples: {len(test_df)}\")\n",
        "\n",
        "    # Create few-shot examples text\n",
        "    fewshot_examples_text = create_fewshot_examples(fewshot_df, TEXT_COLUMN)\n",
        "    fewshot_prompt = create_fewshot_prompt(fewshot_examples_text, is_cot=False)\n",
        "\n",
        "    fewshot_cot_prompt = create_fewshot_prompt(fewshot_examples_text, is_cot=True)\n",
        "\n",
        "    # Choose which experiments to run\n",
        "    experiments = [\n",
        "        # Uncomment the experiments you want to run\n",
        "\n",
        "        # Zero-shot with Claude Sonnet-ran this\n",
        "        # (ZERO_SHOT_PROMPT, MODEL_SONNET, \"Zero-Shot_Claude-Sonnet\")\n",
        "\n",
        "        # Zero-shot with Claude Opus (more powerful but more expensive)\n",
        "        # (ZERO_SHOT_PROMPT, MODEL_OPUS, \"Zero-Shot_Claude-Opus\"),\n",
        "\n",
        "        # Zero-shot with CoT\n",
        "        (ZERO_SHOT_COT_PROMPT, MODEL_SONNET, \"Zero-Shot-CoT_Claude-Sonnet\"),\n",
        "        # (ZERO_SHOT_COT_PROMPT, MODEL_OPUS, \"Zero-Shot-CoT_Claude-Opus\"),\n",
        "\n",
        "        # Few-shot-ran this\n",
        "        (fewshot_prompt, MODEL_SONNET, \"Few-Shot_Claude-Sonnet\"),\n",
        "        # (fewshot_prompt, MODEL_OPUS, \"Few-Shot_Claude-Opus\"),\n",
        "\n",
        "        # Few-shot with CoT\n",
        "        (fewshot_cot_prompt, MODEL_SONNET, \"Few-Shot-CoT_Claude-Sonnet\")\n",
        "        # (fewshot_cot_prompt, MODEL_OPUS, \"Few-Shot-CoT_Claude-Opus\"),\n",
        "    ]\n",
        "\n",
        "    # Run experiments\n",
        "    all_results = []\n",
        "    for prompt_template, model, approach_name in experiments:\n",
        "        results_df = classify_dataset(test_df, TEXT_COLUMN, prompt_template, model, approach_name)\n",
        "        all_results.append(results_df)\n",
        "\n",
        "        # Save individual results\n",
        "        results_df.to_csv(f'results_{approach_name}.csv', index=False)\n",
        "        print(f\"Saved: results_{approach_name}.csv\")\n",
        "\n",
        "    # Combine all results\n",
        "    if all_results:\n",
        "        combined_results = pd.concat(all_results, ignore_index=True)\n",
        "        combined_results.to_csv('all_results_combined.csv', index=False)\n",
        "        print(\"\\nAll results saved to: all_results_combined.csv\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLRIr7RJ2HT8",
        "outputId": "efbeb9d0-c880-4f77-a66f-dc64651925c5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n",
            "Few-shot examples: 20\n",
            "Test samples: 168\n",
            "\n",
            "============================================================\n",
            "Running Zero-Shot-CoT_Claude-Sonnet with claude-sonnet-4-20250514\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Classifying: 100%|██████████| 168/168 [18:00<00:00,  6.43s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: results_Zero-Shot-CoT_Claude-Sonnet.csv\n",
            "\n",
            "============================================================\n",
            "Running Few-Shot_Claude-Sonnet with claude-sonnet-4-20250514\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Classifying: 100%|██████████| 168/168 [32:58<00:00, 11.77s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: results_Few-Shot_Claude-Sonnet.csv\n",
            "\n",
            "============================================================\n",
            "Running Few-Shot-CoT_Claude-Sonnet with claude-sonnet-4-20250514\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Classifying: 100%|██████████| 168/168 [34:11<00:00, 12.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: results_Few-Shot-CoT_Claude-Sonnet.csv\n",
            "\n",
            "All results saved to: all_results_combined.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}