{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO1JmXuBp84NnqgOETloL6p"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KisH1KicpOEt","executionInfo":{"status":"ok","timestamp":1770762099355,"user_tz":300,"elapsed":19296,"user":{"displayName":"Nadia","userId":"17436501635847667941"}},"outputId":"c3f85672-ebd3-4d3d-da5e-297bbd0709e4"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!mkdir -p '/content/drive/MyDrive/Colab Notebooks/svm_classification/outputs'"],"metadata":{"id":"jUcYPA85qN1H","executionInfo":{"status":"ok","timestamp":1770762341517,"user_tz":300,"elapsed":944,"user":{"displayName":"Nadia","userId":"17436501635847667941"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","execution_count":3,"metadata":{"id":"DVzPQg99LNav","executionInfo":{"status":"ok","timestamp":1770762361777,"user_tz":300,"elapsed":2234,"user":{"displayName":"Nadia","userId":"17436501635847667941"}}},"outputs":[],"source":["\"\"\"\n","SVM Classification with Trigrams\n","=================================\n","Train an SVM classifier on your labeled samples using trigram features.\n","\n","Difference from previous model:\n","- Previous: TF-IDF with unigrams + bigrams (1,2)\n","- This: TF-IDF with trigrams (3,3) or combined (1,3)\n","\"\"\"\n","\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.svm import SVC\n","from sklearn.metrics import (classification_report, confusion_matrix,\n","                             accuracy_score, f1_score, precision_score, recall_score)\n","import re\n","import pickle\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","# Update this to your Google Drive path\n","DATA_PATH = '/content/drive/MyDrive/Colab Notebooks/svm_classification/manual_label_batch1_updated.csv'\n","\n","# Update outputs to save in the same folder\n","MODEL_SAVE_PATH = '/content/drive/MyDrive/Colab Notebooks/svm_classification/outputs/svm_trigram_model.pkl'\n","VECTORIZER_SAVE_PATH = '/content/drive/MyDrive/Colab Notebooks/svm_classification/outputs/svm_trigram_vectorizer.pkl'\n","CONFUSION_MATRIX_PATH = '/content/drive/MyDrive/Colab Notebooks/svm_classification/outputs/svm_trigram_confusion_matrix.png'\n","\n","# DATA_PATH = 'manual_label_batch1.xlsx'\n","# MODEL_SAVE_PATH = 'outputs/svm_trigram_model.pkl'\n","# VECTORIZER_SAVE_PATH = 'outputs/svm_trigram_vectorizer.pkl'\n","# CONFUSION_MATRIX_PATH = 'outputs/svm_trigram_confusion_matrix.png'\n"]},{"cell_type":"code","source":["# Trigram options:\n","# 'trigrams_only': (3, 3) - only 3-word sequences\n","# 'unigrams_to_trigrams': (1, 3) - words, 2-word, and 3-word sequences\n","NGRAM_TYPE = 'unigrams_to_trigrams'  # Change to 'trigrams_only' if you want only trigrams\n","\n","TEST_SIZE = 0.2\n","RANDOM_STATE = 42"],"metadata":{"id":"YroZTZ6_Lxf9","executionInfo":{"status":"ok","timestamp":1770762367216,"user_tz":300,"elapsed":12,"user":{"displayName":"Nadia","userId":"17436501635847667941"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# preprocessing\n","def preprocess_text(text):\n","    \"\"\"Clean text data\"\"\"\n","    text = str(text).lower()\n","    text = re.sub(r'http\\S+|www.\\S+', '', text)\n","    text = re.sub(r'\\s+', ' ', text).strip()\n","    return text\n","\n","\n","def handle_multilabels(df):\n","    \"\"\"Take first label from multi-label samples\"\"\"\n","    print(\"\\nHandling multi-label samples...\")\n","    multi_label_mask = df['label'].astype(str).str.contains(',')\n","    multi_label_count = multi_label_mask.sum()\n","\n","    if multi_label_count > 0:\n","        print(f\"  Found {multi_label_count} multi-label samples\")\n","        df['label'] = df['label'].astype(str).apply(lambda x: x.split(',')[0])\n","\n","    df['label'] = df['label'].astype(int)\n","    return df"],"metadata":{"id":"EjZlOno7L9Hi","executionInfo":{"status":"ok","timestamp":1770762369612,"user_tz":300,"elapsed":2,"user":{"displayName":"Nadia","userId":"17436501635847667941"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# MAIN TRAINING FUNCTION\n","# ============================================================================\n","\n","def train_svm_trigram():\n","    \"\"\"Train SVM with trigram features\"\"\"\n","\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"SVM CLASSIFICATION WITH TRIGRAMS\")\n","    print(\"=\"*80)\n","\n","    # -------------------------------------------------------------------------\n","    # 1. LOAD DATA\n","    # -------------------------------------------------------------------------\n","    print(\"\\n[1/7] Loading data...\")\n","    df = pd.read_csv(DATA_PATH)\n","    print(f\"  Loaded {len(df)} samples\")\n","    print(f\"  Columns: {df.columns.tolist()}\")\n","\n","    # -------------------------------------------------------------------------\n","    # 2. PREPROCESS\n","    # -------------------------------------------------------------------------\n","    print(\"\\n[2/7] Preprocessing text...\")\n","    df['text_processed'] = df['text'].apply(preprocess_text)\n","    df = handle_multilabels(df)\n","\n","    print(f\"\\n  Label distribution:\")\n","    print(df['label'].value_counts().sort_index())\n","\n","    # -------------------------------------------------------------------------\n","    # 3. TRAIN-TEST SPLIT\n","    # -------------------------------------------------------------------------\n","    print(f\"\\n[3/7] Splitting data (test size: {TEST_SIZE})...\")\n","    X = df['text_processed'].values\n","    y = df['label'].values\n","\n","    X_train, X_test, y_train, y_test = train_test_split(\n","        X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y\n","    )\n","\n","    print(f\"  Training set: {len(X_train)} samples\")\n","    print(f\"  Test set: {len(X_test)} samples\")\n","\n","    # -------------------------------------------------------------------------\n","    # 4. FEATURE EXTRACTION WITH TRIGRAMS\n","    # -------------------------------------------------------------------------\n","    print(f\"\\n[4/7] Extracting features...\")\n","    print(f\"  N-gram type: {NGRAM_TYPE}\")\n","\n","    if NGRAM_TYPE == 'trigrams_only':\n","        ngram_range = (3, 3)\n","        print(f\"  Using: trigrams only (3-word sequences)\")\n","    else:  # unigrams_to_trigrams\n","        ngram_range = (1, 3)\n","        print(f\"  Using: unigrams + bigrams + trigrams\")\n","\n","    vectorizer = TfidfVectorizer(\n","        max_features=1000,  # Increased for trigrams\n","        min_df=2,\n","        max_df=0.8,\n","        ngram_range=ngram_range,\n","        stop_words='english'\n","    )\n","\n","    X_train_tfidf = vectorizer.fit_transform(X_train)\n","    X_test_tfidf = vectorizer.transform(X_test)\n","\n","    print(f\"   Feature matrix shape (train): {X_train_tfidf.shape}\")\n","    print(f\"   Feature matrix shape (test): {X_test_tfidf.shape}\")\n","    print(f\"   Number of features: {len(vectorizer.get_feature_names_out())}\")\n","\n","    # Show sample trigrams\n","    feature_names = vectorizer.get_feature_names_out()\n","    trigram_features = [f for f in feature_names if len(f.split()) == 3]\n","    if trigram_features:\n","        print(f\"\\n  Sample trigrams extracted:\")\n","        for i, tg in enumerate(trigram_features[:5], 1):\n","            print(f\"    {i}. '{tg}'\")\n","\n","    # -------------------------------------------------------------------------\n","    # 5. TRAIN SVM MODEL\n","    # -------------------------------------------------------------------------\n","    print(f\"\\n[5/7] Training SVM classifier...\")\n","\n","    # Try different kernels\n","    kernels = ['linear', 'rbf']\n","    results = {}\n","\n","    for kernel in kernels:\n","        print(f\"\\n  Training SVM with {kernel} kernel...\")\n","\n","        model = SVC(\n","            kernel=kernel,\n","            C=1.0,\n","            random_state=RANDOM_STATE,\n","            class_weight='balanced',\n","            probability=True  # Enable probability estimates\n","        )\n","\n","        model.fit(X_train_tfidf, y_train)\n","\n","        # Predict\n","        y_pred = model.predict(X_test_tfidf)\n","\n","        # Evaluate\n","        accuracy = accuracy_score(y_test, y_pred)\n","        f1_weighted = f1_score(y_test, y_pred, average='weighted')\n","        f1_macro = f1_score(y_test, y_pred, average='macro')\n","\n","        results[kernel] = {\n","            'model': model,\n","            'accuracy': accuracy,\n","            'f1_weighted': f1_weighted,\n","            'f1_macro': f1_macro,\n","            'predictions': y_pred\n","        }\n","\n","        print(f\"    Accuracy: {accuracy:.4f}\")\n","        print(f\"    F1 (Weighted): {f1_weighted:.4f}\")\n","        print(f\"    F1 (Macro): {f1_macro:.4f}\")\n","\n","    # Select best kernel\n","    best_kernel = max(results, key=lambda k: results[k]['f1_weighted'])\n","    best_model = results[best_kernel]['model']\n","    best_predictions = results[best_kernel]['predictions']\n","\n","    print(f\"\\n   Best kernel: {best_kernel}\")\n","    print(f\"   Best F1 score: {results[best_kernel]['f1_weighted']:.4f}\")\n","\n","    # -------------------------------------------------------------------------\n","    # 6. DETAILED EVALUATION\n","    # -------------------------------------------------------------------------\n","    print(f\"\\n[6/7] Evaluating best model...\")\n","\n","    print(f\"\\n  Classification Report:\")\n","    print(classification_report(y_test, best_predictions))\n","\n","    # Confusion Matrix\n","    cm = confusion_matrix(y_test, best_predictions)\n","    print(f\"\\n  Confusion Matrix:\")\n","    print(cm)\n","\n","    # Plot confusion matrix\n","    plt.figure(figsize=(10, 8))\n","    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n","    plt.title(f'Confusion Matrix - SVM with Trigrams ({best_kernel} kernel)')\n","    plt.ylabel('True Label')\n","    plt.xlabel('Predicted Label')\n","    plt.savefig(CONFUSION_MATRIX_PATH, dpi=300, bbox_inches='tight')\n","    plt.close()\n","    print(f\"\\n   Confusion matrix saved: {CONFUSION_MATRIX_PATH}\")\n","\n","    # -------------------------------------------------------------------------\n","    # 7. SAVE MODEL\n","    # -------------------------------------------------------------------------\n","    print(f\"\\n[7/7] Saving model...\")\n","\n","    with open(MODEL_SAVE_PATH, 'wb') as f:\n","        pickle.dump(best_model, f)\n","    print(f\"   Model saved: {MODEL_SAVE_PATH}\")\n","\n","    with open(VECTORIZER_SAVE_PATH, 'wb') as f:\n","        pickle.dump(vectorizer, f)\n","    print(f\"  Vectorizer saved: {VECTORIZER_SAVE_PATH}\")\n","\n","    # -------------------------------------------------------------------------\n","    # FINAL SUMMARY\n","    # -------------------------------------------------------------------------\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"TRAINING COMPLETE!\")\n","    print(\"=\"*80)\n","\n","    print(f\"\\n Results Summary:\")\n","    print(f\"  Model: SVM ({best_kernel} kernel)\")\n","    print(f\"  Features: {NGRAM_TYPE}\")\n","    print(f\"  Accuracy: {results[best_kernel]['accuracy']:.2%}\")\n","    print(f\"  F1 Score (Weighted): {results[best_kernel]['f1_weighted']:.4f}\")\n","    print(f\"  F1 Score (Macro): {results[best_kernel]['f1_macro']:.4f}\")\n","\n","    print(f\"\\n Files Created:\")\n","    print(f\"  1. {MODEL_SAVE_PATH}\")\n","    print(f\"  2. {VECTORIZER_SAVE_PATH}\")\n","    print(f\"  3. {CONFUSION_MATRIX_PATH}\")\n","\n","    print(f\"\\n Comparison with Previous Model:\")\n","    print(f\"  Previous: Logistic Regression with unigrams+bigrams → 66.67% accuracy\")\n","    print(f\"  Current:  SVM with {NGRAM_TYPE} → {results[best_kernel]['accuracy']:.2%} accuracy\")\n","\n","    if results[best_kernel]['accuracy'] > 0.6667:\n","        print(f\"   Improvement with trigrams!\")\n","    elif results[best_kernel]['accuracy'] < 0.6667:\n","        print(f\"   Lower accuracy - unigrams+bigrams may work better\")\n","    else:\n","        print(f\"   Similar performance\")\n","\n","    return best_model, vectorizer, results\n"],"metadata":{"id":"6wzRHntOMCpX","executionInfo":{"status":"ok","timestamp":1770762416274,"user_tz":300,"elapsed":70,"user":{"displayName":"Nadia","userId":"17436501635847667941"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["#Prediction Function\n","def test_predictions():\n","    \"\"\"Test the trained model on sample texts\"\"\"\n","\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"TESTING PREDICTIONS\")\n","    print(\"=\"*80)\n","\n","    # Load model\n","    with open(MODEL_SAVE_PATH, 'rb') as f:\n","        model = pickle.load(f)\n","    with open(VECTORIZER_SAVE_PATH, 'rb') as f:\n","        vectorizer = pickle.load(f)\n","\n","    # Sample texts\n","    sample_texts = [\n","        \"I'm experiencing severe burnout in my cybersecurity role\",\n","        \"Looking for career advice in IT security\",\n","        \"Just got promoted to senior security analyst\",\n","        \"Dealing with stress and anxiety at work\"\n","    ]\n","\n","    print(\"\\nSample Predictions:\")\n","    print(\"-\" * 80)\n","\n","    for i, text in enumerate(sample_texts, 1):\n","        # Preprocess\n","        processed = preprocess_text(text)\n","\n","        # Vectorize\n","        vectorized = vectorizer.transform([processed])\n","\n","        # Predict\n","        prediction = model.predict(vectorized)[0]\n","        probability = model.predict_proba(vectorized)\n","        confidence = probability.max()\n","\n","        print(f\"\\n{i}. Text: {text[:60]}...\")\n","        print(f\"   Predicted Label: {prediction}\")\n","        print(f\"   Confidence: {confidence:.2%}\")"],"metadata":{"id":"BuOgzAXWN_gq","executionInfo":{"status":"ok","timestamp":1770762420978,"user_tz":300,"elapsed":2,"user":{"displayName":"Nadia","userId":"17436501635847667941"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","\n","    # Train model\n","    model, vectorizer, results = train_svm_trigram()\n","\n","    # Test predictions\n","    print(\"\\n\")\n","    test_predictions()\n","\n","    # Optional: Uncomment to run hyperparameter tuning\n","    # print(\"\\n\")\n","    # print(\"Would you like to run hyperparameter tuning? (takes 5-10 minutes)\")\n","    # response = input(\"Run tuning? (y/n): \")\n","    # if response.lower() == 'y':\n","    #     # Load data again\n","    #     df = pd.read_excel(DATA_PATH)\n","    #     df['text_processed'] = df['text'].apply(preprocess_text)\n","    #     df = handle_multilabels(df)\n","    #     X = df['text_processed'].values\n","    #     y = df['label'].values\n","    #     X_train, X_test, y_train, y_test = train_test_split(\n","    #         X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y\n","    #     )\n","    #     # Vectorize\n","    #     vectorizer = TfidfVectorizer(\n","    #         max_features=1000,\n","    #         min_df=2,\n","    #         max_df=0.8,\n","    #         ngram_range=(1, 3),\n","    #         stop_words='english'\n","    #     )\n","    #     X_train_tfidf = vectorizer.fit_transform(X_train)\n","    #     # Tune\n","    #     tuned_model = tune_svm_hyperparameters(X_train_tfidf, y_train)\n","\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"ALL DONE! \")\n","    print(\"=\"*80)"],"metadata":{"id":"XwiOR5eQOLoQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1770762425025,"user_tz":300,"elapsed":1028,"user":{"displayName":"Nadia","userId":"17436501635847667941"}},"outputId":"ce08a80d-5c9c-41fe-c11e-5cb200217508"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","================================================================================\n","SVM CLASSIFICATION WITH TRIGRAMS\n","================================================================================\n","\n","[1/7] Loading data...\n","  Loaded 188 samples\n","  Columns: ['id', 'text', 'similarity_score', 'label']\n","\n","[2/7] Preprocessing text...\n","\n","Handling multi-label samples...\n","\n","  Label distribution:\n","label\n","0    139\n","1     49\n","Name: count, dtype: int64\n","\n","[3/7] Splitting data (test size: 0.2)...\n","  Training set: 150 samples\n","  Test set: 38 samples\n","\n","[4/7] Extracting features...\n","  N-gram type: unigrams_to_trigrams\n","  Using: unigrams + bigrams + trigrams\n","   Feature matrix shape (train): (150, 1000)\n","   Feature matrix shape (test): (38, 1000)\n","   Number of features: 1000\n","\n","  Sample trigrams extracted:\n","    1. 'feel like im'\n","    2. 'just don know'\n","    3. 'learning new things'\n","    4. 'like cybersecurity job'\n","    5. 'looks like cybersecurity'\n","\n","[5/7] Training SVM classifier...\n","\n","  Training SVM with linear kernel...\n","    Accuracy: 0.8947\n","    F1 (Weighted): 0.8976\n","    F1 (Macro): 0.8721\n","\n","  Training SVM with rbf kernel...\n","    Accuracy: 0.8684\n","    F1 (Weighted): 0.8519\n","    F1 (Macro): 0.7923\n","\n","   Best kernel: linear\n","   Best F1 score: 0.8976\n","\n","[6/7] Evaluating best model...\n","\n","  Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.96      0.89      0.93        28\n","           1       0.75      0.90      0.82        10\n","\n","    accuracy                           0.89        38\n","   macro avg       0.86      0.90      0.87        38\n","weighted avg       0.91      0.89      0.90        38\n","\n","\n","  Confusion Matrix:\n","[[25  3]\n"," [ 1  9]]\n","\n","   Confusion matrix saved: /content/drive/MyDrive/Colab Notebooks/svm_classification/outputs/svm_trigram_confusion_matrix.png\n","\n","[7/7] Saving model...\n","   Model saved: /content/drive/MyDrive/Colab Notebooks/svm_classification/outputs/svm_trigram_model.pkl\n","  Vectorizer saved: /content/drive/MyDrive/Colab Notebooks/svm_classification/outputs/svm_trigram_vectorizer.pkl\n","\n","================================================================================\n","TRAINING COMPLETE!\n","================================================================================\n","\n"," Results Summary:\n","  Model: SVM (linear kernel)\n","  Features: unigrams_to_trigrams\n","  Accuracy: 89.47%\n","  F1 Score (Weighted): 0.8976\n","  F1 Score (Macro): 0.8721\n","\n"," Files Created:\n","  1. /content/drive/MyDrive/Colab Notebooks/svm_classification/outputs/svm_trigram_model.pkl\n","  2. /content/drive/MyDrive/Colab Notebooks/svm_classification/outputs/svm_trigram_vectorizer.pkl\n","  3. /content/drive/MyDrive/Colab Notebooks/svm_classification/outputs/svm_trigram_confusion_matrix.png\n","\n"," Comparison with Previous Model:\n","  Previous: Logistic Regression with unigrams+bigrams → 66.67% accuracy\n","  Current:  SVM with unigrams_to_trigrams → 89.47% accuracy\n","   Improvement with trigrams!\n","\n","\n","\n","================================================================================\n","TESTING PREDICTIONS\n","================================================================================\n","\n","Sample Predictions:\n","--------------------------------------------------------------------------------\n","\n","1. Text: I'm experiencing severe burnout in my cybersecurity role...\n","   Predicted Label: 1\n","   Confidence: 86.95%\n","\n","2. Text: Looking for career advice in IT security...\n","   Predicted Label: 1\n","   Confidence: 60.53%\n","\n","3. Text: Just got promoted to senior security analyst...\n","   Predicted Label: 0\n","   Confidence: 53.71%\n","\n","4. Text: Dealing with stress and anxiety at work...\n","   Predicted Label: 1\n","   Confidence: 50.00%\n","\n","================================================================================\n","ALL DONE! \n","================================================================================\n"]}]}]}