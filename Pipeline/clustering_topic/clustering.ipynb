{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f57487d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# load the data \u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mposts_processed1.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# will do a clustering on the post \"cleaned text\" column\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "# load the data \n",
    "import pandas as pd\n",
    "df = pd.read_csv('posts_processed1.csv')\n",
    "\n",
    "# will do a clustering on the post \"cleaned text\" column\n",
    "\n",
    "TEXT_COL = \"cleaned_text\" if \"cleaned_text\" in df.columns else \"text\"\n",
    "docs = df[TEXT_COL].fillna(\"\").astype(str).tolist()\n",
    "\n",
    "# optional: dropping  super short docs (helps topic quality)\n",
    "min_chars = 40\n",
    "keep_mask = df[TEXT_COL].fillna(\"\").astype(str).str.len() >= min_chars\n",
    "df_small = df[keep_mask].copy()\n",
    "docs_small = df_small[TEXT_COL].fillna(\"\").astype(str).tolist()\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9f7f1f",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.12' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# topic model for clustering, find a better cybersecurity embedding model \n",
    "from sentence_transformers import SentenceTransformer\n",
    "from bertopic import BERTopic\n",
    "\n",
    "from transformers import pipeline\n",
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "topic_model = BERTopic(\n",
    "    embedding_model=embedder,\n",
    "    calculate_probabilities=True,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"fitting topic model...\")\n",
    "topics, probs = topic_model.fit_transform(docs_small)\n",
    "df_small[\"topic_id\"] = topics\n",
    "df_small[\"topic_prob\"] = [float(p.max()) if p is not None else None for p in probs]\n",
    "\n",
    "# topic summary table\n",
    "topic_info = topic_model.get_topic_info()\n",
    "print (\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be98b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Candidate labels (edit/extend to match your paper's taxonomy)\n",
    "CANDIDATE_LABELS = [\n",
    "    \"workload and time pressure\",\n",
    "    \"on-call fatigue and overtime\",\n",
    "    \"sleep disruption and exhaustion\",\n",
    "    \"burnout and emotional exhaustion\",\n",
    "    \"frustration and helplessness\",\n",
    "    \"organizational constraints and bureaucracy\",\n",
    "    \"poor leadership and lack of support\",\n",
    "    \"moral distress (can't do the right thing due to constraints)\",\n",
    "    \"moral injury (betrayal/disillusionment, erosion of purpose/trust)\",\n",
    "    \"hero complex (sole responsibility, can't disengage)\",\n",
    "    \"imposter syndrome and anxiety\",\n",
    "    \"team conflict and communication issues\",\n",
    "    \"career stagnation and low recognition\",\n",
    "    \"incident response stress\",\n",
    "    \"tools, process, and technical debt stress\",\n",
    "    \"training and skill pressure\"\n",
    "]\n",
    "\n",
    "# zero-shot classifier (NLI)\n",
    "# If you have GPU: it will run faster; otherwise still works on CPU\n",
    "zsc = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "print(\"classifying topics...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ad2d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_topic_text(topic_id, n_words=12, n_examples=3):\n",
    "    \"\"\"Combine top keywords + a few representative posts as the text to label.\"\"\"\n",
    "    words = topic_model.get_topic(topic_id)\n",
    "    if not words:\n",
    "        return \"\"\n",
    "    top_words = [w for w, _ in words[:n_words]]\n",
    "\n",
    "    # representative posts (BERTopic helper)\n",
    "    # note: this returns a DF with a \"Document\" column in recent versions\n",
    "    rep = topic_model.get_representative_docs(topic_id)\n",
    "    examples = rep[:n_examples] if rep else []\n",
    "\n",
    "    text = \"Topic keywords: \" + \", \".join(top_words) + \"\\n\\nExamples:\\n\" + \"\\n---\\n\".join(examples)\n",
    "    return text\n",
    "\n",
    "# Label each topic (skip outlier topic -1)\n",
    "topic_id_to_label = {}\n",
    "for tid in topic_info[\"Topic\"].tolist():\n",
    "    if tid == -1:\n",
    "        topic_id_to_label[tid] = \"outlier/misc\"\n",
    "        continue\n",
    "\n",
    "    topic_text = build_topic_text(tid)\n",
    "    if not topic_text.strip():\n",
    "        topic_id_to_label[tid] = \"misc\"\n",
    "        continue\n",
    "\n",
    "    pred = zsc(topic_text, CANDIDATE_LABELS, multi_label=False)\n",
    "    topic_id_to_label[tid] = pred[\"labels\"][0]  # top label\n",
    "\n",
    "# attach labels to per-post dataframe\n",
    "df_small[\"topic_label\"] = df_small[\"topic_id\"].map(topic_id_to_label)\n",
    "\n",
    "# attach labels to topic_info summary table\n",
    "topic_info[\"topic_label\"] = topic_info[\"Topic\"].map(topic_id_to_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58618812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Save results\n",
    "# -------------------------\n",
    "df_small.to_csv(\"data/posts_with_topics.csv\", index=False)\n",
    "topic_info.to_csv(\"data/topic_info.csv\", index=False)\n",
    "\n",
    "print(\"Saved:\")\n",
    "print(\" posts_with_topics.csv\")\n",
    "print(\" topic_info.csv\")\n",
    "print(\"\\nTop topics:\")\n",
    "print(topic_info.head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
