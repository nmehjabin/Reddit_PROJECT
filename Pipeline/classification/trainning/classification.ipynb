{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b82f92f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nText Classification Model trainning \\nSteps \\n1. Data Loading & Exploration\\n2. Data Preprocessing\\n3. Handling Multi-labels\\n4. Train-Test Split\\n5. Feature Extraction (TF-IDF, Word Embeddings)\\n6. Model Training (Multiple approaches)\\n7. Model Evaluation\\n8. Hyperparameter Tuning\\n9. Model Saving\\n10. Prediction on New Data\\n\\n\\nlibraries \\npip install tensorflow scikit-learn pandas numpy matplotlib seaborn openpyxl xlrd imbalanced-learn --break-system-packages\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Text Classification Model trainning \n",
    "Steps \n",
    "1. Data Loading & Exploration\n",
    "2. Data Preprocessing\n",
    "3. Handling Multi-labels\n",
    "4. Train-Test Split\n",
    "5. Feature Extraction (TF-IDF, Word Embeddings)\n",
    "6. Model Training (Multiple approaches)\n",
    "7. Model Evaluation\n",
    "8. Hyperparameter Tuning\n",
    "9. Model Saving\n",
    "10. Prediction on New Data\n",
    "\n",
    "\n",
    "libraries \n",
    "pip install tensorflow scikit-learn pandas numpy matplotlib seaborn openpyxl xlrd imbalanced-learn --break-system-packages\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4d94352",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-26 23:55:49.151695: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2026-01-26 23:55:49.844688: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2026-01-26 23:55:53.831714: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All necessary libraries are imported successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, \n",
    "                             accuracy_score, f1_score, precision_score, recall_score)\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# For deep learning (optional - neural networks)\n",
    "try:\n",
    "    from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "    from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import Dense, Embedding, LSTM, Dropout\n",
    "    KERAS_AVAILABLE = True\n",
    "except ImportError:\n",
    "    KERAS_AVAILABLE = False\n",
    "    print(\"TensorFlow/Keras not available. Will skip deep learning models.\")\n",
    "\n",
    "\n",
    "print(\"All necessary libraries are imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3a7dcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1: DATA LOADING & EXPLORATION\n",
    "\n",
    "def load_and_explore_data(file_path):\n",
    "    \"\"\"Load data and perform initial exploration\"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    print(\"STEP 1: DATA LOADING & EXPLORATION\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Load data\n",
    "    df = pd.read_excel(file_path)\n",
    "    \n",
    "    print(f\"\\nDataset shape: {df.shape}\")\n",
    "    print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "    print(f\"\\nFirst few rows:\")\n",
    "    print(df.head())\n",
    "    \n",
    "    print(f\"\\nLabel distribution:\")\n",
    "    print(df['label'].value_counts())\n",
    "    \n",
    "    print(f\"\\nMissing values:\")\n",
    "    print(df.isnull().sum())\n",
    "    \n",
    "    print(f\"\\nText length statistics:\")\n",
    "    df['text_length'] = df['text'].apply(lambda x: len(str(x)))\n",
    "    print(df['text_length'].describe())\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdfc1bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 2: DATA PREPROCESSING\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Clean and preprocess text data\"\"\"\n",
    "    # Convert to lowercase\n",
    "    text = str(text).lower()\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www.\\S+', '', text)\n",
    "    \n",
    "    # Remove special characters and digits (optional - depending on your use case)\n",
    "    # text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    \n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e93b19b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_multilabels(df, strategy='first'):\n",
    "    \"\"\"\n",
    "    Handle multi-label samples\n",
    "    \n",
    "    Strategies:\n",
    "    - 'first': Take the first label\n",
    "    - 'remove': Remove multi-label samples\n",
    "    - 'separate': Create separate samples for each label (data augmentation)\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"STEP 3: HANDLING MULTI-LABELS\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Identify multi-label samples\n",
    "    multi_label_mask = df['label'].astype(str).str.contains(',')\n",
    "    multi_label_count = multi_label_mask.sum()\n",
    "    \n",
    "    print(f\"\\nMulti-label samples found: {multi_label_count}\")\n",
    "    print(f\"Multi-label samples: {df[multi_label_mask]['label'].unique()}\")\n",
    "    \n",
    "    if strategy == 'first':\n",
    "        print(\"\\nStrategy: Taking first label from multi-label samples\")\n",
    "        df['label'] = df['label'].astype(str).apply(lambda x: x.split(',')[0])\n",
    "        \n",
    "    elif strategy == 'remove':\n",
    "        print(\"\\nStrategy: Removing multi-label samples\")\n",
    "        df = df[~multi_label_mask].copy()\n",
    "        \n",
    "    elif strategy == 'separate':\n",
    "        print(\"\\nStrategy: Creating separate samples for each label\")\n",
    "        new_rows = []\n",
    "        for idx, row in df[multi_label_mask].iterrows():\n",
    "            labels = str(row['label']).split(',')\n",
    "            for label in labels:\n",
    "                new_row = row.copy()\n",
    "                new_row['label'] = label.strip()\n",
    "                new_rows.append(new_row)\n",
    "        \n",
    "        # Remove original multi-label rows and add new rows\n",
    "        df = pd.concat([df[~multi_label_mask], pd.DataFrame(new_rows)], ignore_index=True)\n",
    "    \n",
    "    # Convert labels to integers\n",
    "    df['label'] = df['label'].astype(int)\n",
    "    \n",
    "    print(f\"\\nFinal label distribution:\")\n",
    "    print(df['label'].value_counts().sort_index())\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b3b4c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 4: TRAIN-TEST SPLIT\n",
    "def split_data(df, test_size=0.2, random_state=42, stratify=True):\n",
    "    \"\"\"Split data into train and test sets\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"STEP 4: TRAIN-TEST SPLIT\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    X = df['text'].values\n",
    "    y = df['label'].values\n",
    "    \n",
    "    # Use stratified split to maintain class distribution\n",
    "    if stratify:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=test_size, random_state=random_state, stratify=y\n",
    "        )\n",
    "    else:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=test_size, random_state=random_state\n",
    "        )\n",
    "    \n",
    "    print(f\"\\nTraining set size: {len(X_train)}\")\n",
    "    print(f\"Test set size: {len(X_test)}\")\n",
    "    print(f\"\\nTraining set label distribution:\")\n",
    "    print(pd.Series(y_train).value_counts().sort_index())\n",
    "    print(f\"\\nTest set label distribution:\")\n",
    "    print(pd.Series(y_test).value_counts().sort_index())\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c61d3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 5: FEATURE EXTRACTION\n",
    "\n",
    "def extract_features_tfidf(X_train, X_test, max_features=1000):\n",
    "    \"\"\"Extract TF-IDF features\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"STEP 5: FEATURE EXTRACTION (TF-IDF)\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    vectorizer = TfidfVectorizer(\n",
    "        max_features=max_features,\n",
    "        min_df=2,  # Ignore terms that appear in less than 2 documents\n",
    "        max_df=0.8,  # Ignore terms that appear in more than 80% of documents\n",
    "        ngram_range=(1, 2),  # Use unigrams and bigrams\n",
    "        stop_words='english'\n",
    "    )\n",
    "    \n",
    "    X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "    X_test_tfidf = vectorizer.transform(X_test)\n",
    "    \n",
    "    print(f\"\\nTF-IDF matrix shape (train): {X_train_tfidf.shape}\")\n",
    "    print(f\"TF-IDF matrix shape (test): {X_test_tfidf.shape}\")\n",
    "    print(f\"Number of features: {len(vectorizer.get_feature_names_out())}\")\n",
    "    \n",
    "    return X_train_tfidf, X_test_tfidf, vectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2924fae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 6: MODEL TRAINING\n",
    "\n",
    "def train_models(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"Train multiple models and compare performance\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"STEP 6: MODEL TRAINING\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    models = {\n",
    "        'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42, class_weight='balanced'),\n",
    "        'Naive Bayes': MultinomialNB(),\n",
    "        'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced'),\n",
    "        'SVM': SVC(kernel='linear', random_state=42, class_weight='balanced')\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        print(f\"\\n{'='*40}\")\n",
    "        print(f\"Training {name}...\")\n",
    "        print(f\"{'='*40}\")\n",
    "        \n",
    "        # Train\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Evaluate\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        f1_weighted = f1_score(y_test, y_pred, average='weighted')\n",
    "        f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "        \n",
    "        print(f\"\\nAccuracy: {accuracy:.4f}\")\n",
    "        print(f\"F1 Score (Weighted): {f1_weighted:.4f}\")\n",
    "        print(f\"F1 Score (Macro): {f1_macro:.4f}\")\n",
    "        \n",
    "        print(f\"\\nClassification Report:\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        \n",
    "        results[name] = {\n",
    "            'model': model,\n",
    "            'accuracy': accuracy,\n",
    "            'f1_weighted': f1_weighted,\n",
    "            'f1_macro': f1_macro,\n",
    "            'predictions': y_pred\n",
    "        }\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f12082c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 7: MODEL EVALUATION\n",
    "\n",
    "def evaluate_best_model(results, y_test):\n",
    "    \"\"\"Evaluate and visualize the best model\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"STEP 7: MODEL EVALUATION\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Find best model based on F1 weighted score\n",
    "    best_model_name = max(results, key=lambda k: results[k]['f1_weighted'])\n",
    "    best_model = results[best_model_name]['model']\n",
    "    best_predictions = results[best_model_name]['predictions']\n",
    "    \n",
    "    print(f\"\\nBest Model: {best_model_name}\")\n",
    "    print(f\"Accuracy: {results[best_model_name]['accuracy']:.4f}\")\n",
    "    print(f\"F1 Score (Weighted): {results[best_model_name]['f1_weighted']:.4f}\")\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, best_predictions)\n",
    "    \n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(cm)\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f'Confusion Matrix - {best_model_name}')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.savefig('confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(\"\\nConfusion matrix saved to: confusion_matrix.png\")\n",
    "    \n",
    "    return best_model_name, best_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f9eb688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 8: HYPERPARAMETER TUNING\n",
    "def tune_hyperparameters(X_train, y_train, model_type='logistic'):\n",
    "    \"\"\"Perform hyperparameter tuning\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"STEP 8: HYPERPARAMETER TUNING\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    if model_type == 'logistic':\n",
    "        model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "        param_grid = {\n",
    "            'C': [0.01, 0.1, 1, 10],\n",
    "            'penalty': ['l1', 'l2'],\n",
    "            'solver': ['liblinear', 'saga'],\n",
    "            'class_weight': ['balanced', None]\n",
    "        }\n",
    "    elif model_type == 'random_forest':\n",
    "        model = RandomForestClassifier(random_state=42)\n",
    "        param_grid = {\n",
    "            'n_estimators': [50, 100, 200],\n",
    "            'max_depth': [10, 20, None],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'class_weight': ['balanced', None]\n",
    "        }\n",
    "    else:\n",
    "        raise ValueError(\"model_type must be 'logistic' or 'random_forest'\")\n",
    "    \n",
    "    print(f\"\\nTuning {model_type} model...\")\n",
    "    print(f\"Parameter grid: {param_grid}\")\n",
    "    \n",
    "    grid_search = GridSearchCV(\n",
    "        model, \n",
    "        param_grid, \n",
    "        cv=5,  # 5-fold cross-validation\n",
    "        scoring='f1_weighted',\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    print(f\"\\nBest parameters: {grid_search.best_params_}\")\n",
    "    print(f\"Best cross-validation F1 score: {grid_search.best_score_:.4f}\")\n",
    "    \n",
    "    return grid_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5e90eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 9: MODEL SAVING\n",
    "\n",
    "def save_model(model, vectorizer, filepath_model, filepath_vectorizer):\n",
    "    \"\"\"Save trained model and vectorizer\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"STEP 9: SAVING MODEL\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    import pickle\n",
    "    \n",
    "    # Save model\n",
    "    with open(filepath_model, 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "    print(f\"\\nModel saved to: {filepath_model}\")\n",
    "    \n",
    "    # Save vectorizer\n",
    "    with open(filepath_vectorizer, 'wb') as f:\n",
    "        pickle.dump(vectorizer, f)\n",
    "    print(f\"Vectorizer saved to: {filepath_vectorizer}\")\n",
    "\n",
    "\n",
    "def load_model(filepath_model, filepath_vectorizer):\n",
    "    \"\"\"Load saved model and vectorizer\"\"\"\n",
    "    import pickle\n",
    "    \n",
    "    with open(filepath_model, 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "    \n",
    "    with open(filepath_vectorizer, 'rb') as f:\n",
    "        vectorizer = pickle.load(f)\n",
    "    \n",
    "    return model, vectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb477395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 10: PREDICTION ON NEW DATA\n",
    "\n",
    "def predict_new_data(model, vectorizer, new_texts):\n",
    "    \"\"\"Predict labels for new text data\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"STEP 10: PREDICTION ON NEW DATA\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Preprocess\n",
    "    new_texts_processed = [preprocess_text(text) for text in new_texts]\n",
    "    \n",
    "    # Vectorize\n",
    "    new_texts_tfidf = vectorizer.transform(new_texts_processed)\n",
    "    \n",
    "    # Predict\n",
    "    predictions = model.predict(new_texts_tfidf)\n",
    "    \n",
    "    # Get prediction probabilities (if available)\n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        probabilities = model.predict_proba(new_texts_tfidf)\n",
    "        \n",
    "        for i, (text, pred, prob) in enumerate(zip(new_texts, predictions, probabilities)):\n",
    "            print(f\"\\nText {i+1}: {text[:100]}...\")\n",
    "            print(f\"Predicted Label: {pred}\")\n",
    "            print(f\"Confidence: {max(prob):.4f}\")\n",
    "    else:\n",
    "        for i, (text, pred) in enumerate(zip(new_texts, predictions)):\n",
    "            print(f\"\\nText {i+1}: {text[:100]}...\")\n",
    "            print(f\"Predicted Label: {pred}\")\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e5818bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TEXT CLASSIFICATION MODEL TRAINING PIPELINE\n",
      "================================================================================\n",
      "================================================================================\n",
      "STEP 1: DATA LOADING & EXPLORATION\n",
      "================================================================================\n",
      "\n",
      "Dataset shape: (177, 4)\n",
      "\n",
      "Columns: ['id', 'text', 'similarity_score', 'label']\n",
      "\n",
      "First few rows:\n",
      "        id                                               text  \\\n",
      "0  1g4a7ot  Burn out among Cybersecurity leaders at a frus...   \n",
      "1  1dqiog2  Invitation to Participate in Research Study on...   \n",
      "2  1g49xt4  Dealing with feeling stuck in the security fie...   \n",
      "3  1fqxn7a  How are you doing guys?\\nIs this cybersecurity...   \n",
      "4  1fbdhwo  Hey folks, for those of you working right now,...   \n",
      "\n",
      "   similarity_score label  \n",
      "0          0.437536     1  \n",
      "1          0.400815     0  \n",
      "2          0.281245     0  \n",
      "3          0.316323     1  \n",
      "4          0.377892     2  \n",
      "\n",
      "Label distribution:\n",
      "label\n",
      "0      107\n",
      "1       38\n",
      "2        8\n",
      "6        6\n",
      "3        3\n",
      "9        3\n",
      "7        3\n",
      "5        2\n",
      "7,8      2\n",
      "4        2\n",
      "4,8      1\n",
      "2,9      1\n",
      "1,4      1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Missing values:\n",
      "id                  0\n",
      "text                0\n",
      "similarity_score    0\n",
      "label               0\n",
      "dtype: int64\n",
      "\n",
      "Text length statistics:\n",
      "count     177.000000\n",
      "mean      627.129944\n",
      "std      1004.791515\n",
      "min        11.000000\n",
      "25%        88.000000\n",
      "50%       303.000000\n",
      "75%       727.000000\n",
      "max      9549.000000\n",
      "Name: text_length, dtype: float64\n",
      "\n",
      "================================================================================\n",
      "STEP 2: TEXT PREPROCESSING\n",
      "================================================================================\n",
      "\n",
      "Sample preprocessed text:\n",
      "burn out among cybersecurity leaders at a frustrating high. in a world of high powered ai and evolving threat actors; cyber security leaders are facing significant amounts of burnout and stress. anyone experienced this as well? [\n",
      "\n",
      "================================================================================\n",
      "STEP 3: HANDLING MULTI-LABELS\n",
      "================================================================================\n",
      "\n",
      "Multi-label samples found: 5\n",
      "Multi-label samples: ['7,8' '4,8' '2,9' '1,4']\n",
      "\n",
      "Strategy: Taking first label from multi-label samples\n",
      "\n",
      "Final label distribution:\n",
      "label\n",
      "0    107\n",
      "1     39\n",
      "2      9\n",
      "3      3\n",
      "4      3\n",
      "5      2\n",
      "6      6\n",
      "7      5\n",
      "9      3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "================================================================================\n",
      "STEP 4: TRAIN-TEST SPLIT\n",
      "================================================================================\n",
      "\n",
      "Training set size: 141\n",
      "Test set size: 36\n",
      "\n",
      "Training set label distribution:\n",
      "0    85\n",
      "1    31\n",
      "2     7\n",
      "3     3\n",
      "4     2\n",
      "5     2\n",
      "6     5\n",
      "7     4\n",
      "9     2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test set label distribution:\n",
      "0    22\n",
      "1     8\n",
      "2     2\n",
      "4     1\n",
      "6     1\n",
      "7     1\n",
      "9     1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "================================================================================\n",
      "STEP 5: FEATURE EXTRACTION (TF-IDF)\n",
      "================================================================================\n",
      "\n",
      "TF-IDF matrix shape (train): (141, 500)\n",
      "TF-IDF matrix shape (test): (36, 500)\n",
      "Number of features: 500\n",
      "\n",
      "================================================================================\n",
      "STEP 6: MODEL TRAINING\n",
      "================================================================================\n",
      "\n",
      "========================================\n",
      "Training Logistic Regression...\n",
      "========================================\n",
      "\n",
      "Accuracy: 0.6667\n",
      "F1 Score (Weighted): 0.6695\n",
      "F1 Score (Macro): 0.4827\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.77      0.79        22\n",
      "           1       0.56      0.62      0.59         8\n",
      "           2       0.00      0.00      0.00         2\n",
      "           4       1.00      1.00      1.00         1\n",
      "           6       1.00      1.00      1.00         1\n",
      "           7       0.00      0.00      0.00         1\n",
      "           9       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.67        36\n",
      "   macro avg       0.48      0.49      0.48        36\n",
      "weighted avg       0.67      0.67      0.67        36\n",
      "\n",
      "\n",
      "========================================\n",
      "Training Naive Bayes...\n",
      "========================================\n",
      "\n",
      "Accuracy: 0.6111\n",
      "F1 Score (Weighted): 0.4636\n",
      "F1 Score (Macro): 0.1084\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      1.00      0.76        22\n",
      "           1       0.00      0.00      0.00         8\n",
      "           2       0.00      0.00      0.00         2\n",
      "           4       0.00      0.00      0.00         1\n",
      "           6       0.00      0.00      0.00         1\n",
      "           7       0.00      0.00      0.00         1\n",
      "           9       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.61        36\n",
      "   macro avg       0.09      0.14      0.11        36\n",
      "weighted avg       0.37      0.61      0.46        36\n",
      "\n",
      "\n",
      "========================================\n",
      "Training Random Forest...\n",
      "========================================\n",
      "\n",
      "Accuracy: 0.6944\n",
      "F1 Score (Weighted): 0.6065\n",
      "F1 Score (Macro): 0.3112\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      1.00      0.81        22\n",
      "           1       0.67      0.25      0.36         8\n",
      "           2       0.00      0.00      0.00         2\n",
      "           4       0.00      0.00      0.00         1\n",
      "           6       1.00      1.00      1.00         1\n",
      "           7       0.00      0.00      0.00         1\n",
      "           9       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.69        36\n",
      "   macro avg       0.34      0.32      0.31        36\n",
      "weighted avg       0.60      0.69      0.61        36\n",
      "\n",
      "\n",
      "========================================\n",
      "Training SVM...\n",
      "========================================\n",
      "\n",
      "Accuracy: 0.6667\n",
      "F1 Score (Weighted): 0.6447\n",
      "F1 Score (Macro): 0.3349\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82        22\n",
      "           1       0.45      0.62      0.53         8\n",
      "           2       0.00      0.00      0.00         2\n",
      "           4       0.00      0.00      0.00         1\n",
      "           6       1.00      1.00      1.00         1\n",
      "           7       0.00      0.00      0.00         1\n",
      "           9       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.67        36\n",
      "   macro avg       0.32      0.35      0.33        36\n",
      "weighted avg       0.63      0.67      0.64        36\n",
      "\n",
      "\n",
      "================================================================================\n",
      "STEP 7: MODEL EVALUATION\n",
      "================================================================================\n",
      "\n",
      "Best Model: Logistic Regression\n",
      "Accuracy: 0.6667\n",
      "F1 Score (Weighted): 0.6695\n",
      "\n",
      "Confusion Matrix:\n",
      "[[17  1  4  0  0  0  0]\n",
      " [ 3  5  0  0  0  0  0]\n",
      " [ 1  1  0  0  0  0  0]\n",
      " [ 0  0  0  1  0  0  0]\n",
      " [ 0  0  0  0  1  0  0]\n",
      " [ 0  1  0  0  0  0  0]\n",
      " [ 0  1  0  0  0  0  0]]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/mnt/user-data/outputs/confusion_matrix.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 81\u001b[39m\n\u001b[32m     77\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m5. Try deep learning models if you have more data\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 42\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     39\u001b[39m results = train_models(X_train_tfidf, y_train, X_test_tfidf, y_test)\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# Step 7: Evaluate best model\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m best_model_name, best_model = \u001b[43mevaluate_best_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[38;5;66;03m# Step 8: Hyperparameter tuning (optional - can be slow)\u001b[39;00m\n\u001b[32m     45\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mWould you like to perform hyperparameter tuning? (Recommended for better results)\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 30\u001b[39m, in \u001b[36mevaluate_best_model\u001b[39m\u001b[34m(results, y_test)\u001b[39m\n\u001b[32m     28\u001b[39m plt.ylabel(\u001b[33m'\u001b[39m\u001b[33mTrue Label\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     29\u001b[39m plt.xlabel(\u001b[33m'\u001b[39m\u001b[33mPredicted Label\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m \u001b[43mplt\u001b[49m\u001b[43m.\u001b[49m\u001b[43msavefig\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m/mnt/user-data/outputs/confusion_matrix.png\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdpi\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m300\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox_inches\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtight\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m plt.close()\n\u001b[32m     33\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mConfusion matrix saved to: /mnt/user-data/outputs/confusion_matrix.png\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/myenv/lib/python3.11/site-packages/matplotlib/pyplot.py:1250\u001b[39m, in \u001b[36msavefig\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1247\u001b[39m fig = gcf()\n\u001b[32m   1248\u001b[39m \u001b[38;5;66;03m# savefig default implementation has no return, so mypy is unhappy\u001b[39;00m\n\u001b[32m   1249\u001b[39m \u001b[38;5;66;03m# presumably this is here because subclasses can return?\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1250\u001b[39m res = \u001b[43mfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43msavefig\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[func-returns-value]\u001b[39;00m\n\u001b[32m   1251\u001b[39m fig.canvas.draw_idle()  \u001b[38;5;66;03m# Need this if 'transparent=True', to reset colors.\u001b[39;00m\n\u001b[32m   1252\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/myenv/lib/python3.11/site-packages/matplotlib/figure.py:3490\u001b[39m, in \u001b[36mFigure.savefig\u001b[39m\u001b[34m(self, fname, transparent, **kwargs)\u001b[39m\n\u001b[32m   3488\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m ax \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.axes:\n\u001b[32m   3489\u001b[39m         _recursively_make_axes_transparent(stack, ax)\n\u001b[32m-> \u001b[39m\u001b[32m3490\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcanvas\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprint_figure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/myenv/lib/python3.11/site-packages/matplotlib/backend_bases.py:2186\u001b[39m, in \u001b[36mFigureCanvasBase.print_figure\u001b[39m\u001b[34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[39m\n\u001b[32m   2182\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   2183\u001b[39m     \u001b[38;5;66;03m# _get_renderer may change the figure dpi (as vector formats\u001b[39;00m\n\u001b[32m   2184\u001b[39m     \u001b[38;5;66;03m# force the figure dpi to 72), so we need to set it again here.\u001b[39;00m\n\u001b[32m   2185\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m cbook._setattr_cm(\u001b[38;5;28mself\u001b[39m.figure, dpi=dpi):\n\u001b[32m-> \u001b[39m\u001b[32m2186\u001b[39m         result = \u001b[43mprint_method\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2187\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2188\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfacecolor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfacecolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2189\u001b[39m \u001b[43m            \u001b[49m\u001b[43medgecolor\u001b[49m\u001b[43m=\u001b[49m\u001b[43medgecolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2190\u001b[39m \u001b[43m            \u001b[49m\u001b[43morientation\u001b[49m\u001b[43m=\u001b[49m\u001b[43morientation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2191\u001b[39m \u001b[43m            \u001b[49m\u001b[43mbbox_inches_restore\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_bbox_inches_restore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2192\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2193\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   2194\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m bbox_inches \u001b[38;5;129;01mand\u001b[39;00m restore_bbox:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/myenv/lib/python3.11/site-packages/matplotlib/backend_bases.py:2042\u001b[39m, in \u001b[36mFigureCanvasBase._switch_canvas_and_return_print_method.<locals>.<lambda>\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   2038\u001b[39m     optional_kws = {  \u001b[38;5;66;03m# Passed by print_figure for other renderers.\u001b[39;00m\n\u001b[32m   2039\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mdpi\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mfacecolor\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33medgecolor\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33morientation\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   2040\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mbbox_inches_restore\u001b[39m\u001b[33m\"\u001b[39m}\n\u001b[32m   2041\u001b[39m     skip = optional_kws - {*inspect.signature(meth).parameters}\n\u001b[32m-> \u001b[39m\u001b[32m2042\u001b[39m     print_method = functools.wraps(meth)(\u001b[38;5;28;01mlambda\u001b[39;00m *args, **kwargs: \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2043\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mskip\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m   2044\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Let third-parties do as they see fit.\u001b[39;00m\n\u001b[32m   2045\u001b[39m     print_method = meth\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/myenv/lib/python3.11/site-packages/matplotlib/backends/backend_agg.py:481\u001b[39m, in \u001b[36mFigureCanvasAgg.print_png\u001b[39m\u001b[34m(self, filename_or_obj, metadata, pil_kwargs)\u001b[39m\n\u001b[32m    434\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mprint_png\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename_or_obj, *, metadata=\u001b[38;5;28;01mNone\u001b[39;00m, pil_kwargs=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    435\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    436\u001b[39m \u001b[33;03m    Write the figure to a PNG file.\u001b[39;00m\n\u001b[32m    437\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    479\u001b[39m \u001b[33;03m        *metadata*, including the default 'Software' key.\u001b[39;00m\n\u001b[32m    480\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m481\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_print_pil\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpng\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpil_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/myenv/lib/python3.11/site-packages/matplotlib/backends/backend_agg.py:430\u001b[39m, in \u001b[36mFigureCanvasAgg._print_pil\u001b[39m\u001b[34m(self, filename_or_obj, fmt, pil_kwargs, metadata)\u001b[39m\n\u001b[32m    425\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    426\u001b[39m \u001b[33;03mDraw the canvas, then save it using `.image.imsave` (to which\u001b[39;00m\n\u001b[32m    427\u001b[39m \u001b[33;03m*pil_kwargs* and *metadata* are forwarded).\u001b[39;00m\n\u001b[32m    428\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    429\u001b[39m FigureCanvasAgg.draw(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m430\u001b[39m \u001b[43mmpl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimsave\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    431\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbuffer_rgba\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43mfmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morigin\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupper\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    432\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdpi\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfigure\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdpi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpil_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpil_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/myenv/lib/python3.11/site-packages/matplotlib/image.py:1657\u001b[39m, in \u001b[36mimsave\u001b[39m\u001b[34m(fname, arr, vmin, vmax, cmap, format, origin, dpi, metadata, pil_kwargs)\u001b[39m\n\u001b[32m   1655\u001b[39m pil_kwargs.setdefault(\u001b[33m\"\u001b[39m\u001b[33mformat\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mformat\u001b[39m)\n\u001b[32m   1656\u001b[39m pil_kwargs.setdefault(\u001b[33m\"\u001b[39m\u001b[33mdpi\u001b[39m\u001b[33m\"\u001b[39m, (dpi, dpi))\n\u001b[32m-> \u001b[39m\u001b[32m1657\u001b[39m \u001b[43mimage\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpil_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/myenv/lib/python3.11/site-packages/PIL/Image.py:2585\u001b[39m, in \u001b[36mImage.save\u001b[39m\u001b[34m(self, fp, format, **params)\u001b[39m\n\u001b[32m   2583\u001b[39m         fp = builtins.open(filename, \u001b[33m\"\u001b[39m\u001b[33mr+b\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   2584\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2585\u001b[39m         fp = \u001b[43mbuiltins\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mw+b\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   2586\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2587\u001b[39m     fp = cast(IO[\u001b[38;5;28mbytes\u001b[39m], fp)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/mnt/user-data/outputs/confusion_matrix.png'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# MAIN PIPELINE\n",
    "def main():\n",
    "    \"\"\"Run the complete classification pipeline\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"TEXT CLASSIFICATION MODEL TRAINING PIPELINE\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # File path\n",
    "    data_path = 'manual_label_batch1.xlsx'\n",
    "    \n",
    "    # Step 1: Load data\n",
    "    df = load_and_explore_data(data_path)\n",
    "    \n",
    "    # Step 2: Preprocess text\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"STEP 2: TEXT PREPROCESSING\")\n",
    "    print(\"=\" * 80)\n",
    "    df['text_processed'] = df['text'].apply(preprocess_text)\n",
    "    print(\"\\nSample preprocessed text:\")\n",
    "    print(df['text_processed'].iloc[0])\n",
    "    \n",
    "    # Step 3: Handle multi-labels\n",
    "    df = handle_multilabels(df, strategy='first')  # Change strategy as needed\n",
    "    \n",
    "    # Step 4: Split data\n",
    "    X_train, X_test, y_train, y_test = split_data(df, test_size=0.2)\n",
    "    \n",
    "    # Preprocess train and test texts\n",
    "    X_train_processed = [preprocess_text(text) for text in X_train]\n",
    "    X_test_processed = [preprocess_text(text) for text in X_test]\n",
    "    \n",
    "    # Step 5: Feature extraction\n",
    "    X_train_tfidf, X_test_tfidf, vectorizer = extract_features_tfidf(\n",
    "        X_train_processed, X_test_processed, max_features=500\n",
    "    )\n",
    "    \n",
    "    # Step 6: Train models\n",
    "    results = train_models(X_train_tfidf, y_train, X_test_tfidf, y_test)\n",
    "    \n",
    "    # Step 7: Evaluate best model\n",
    "    best_model_name, best_model = evaluate_best_model(results, y_test)\n",
    "    \n",
    "    # Step 8: Hyperparameter tuning (optional - can be slow)\n",
    "    print(\"\\nWould you like to perform hyperparameter tuning? (Recommended for better results)\")\n",
    "    print(\"Skipping for now - you can uncomment the lines below to enable it\")\n",
    "    # tuned_model = tune_hyperparameters(X_train_tfidf, y_train, model_type='logistic')\n",
    "    # y_pred_tuned = tuned_model.predict(X_test_tfidf)\n",
    "    # print(\"\\nTuned Model Results:\")\n",
    "    # print(classification_report(y_test, y_pred_tuned))\n",
    "    \n",
    "    # Step 9: Save model\n",
    "    save_model(\n",
    "        best_model, \n",
    "        vectorizer, \n",
    "        'best_model.pkl',\n",
    "        'vectorizer.pkl'\n",
    "    )\n",
    "    \n",
    "    # Step 10: Test prediction on new data\n",
    "    sample_texts = [\n",
    "        \"I'm experiencing severe burnout in my cybersecurity role\",\n",
    "        \"Looking for recommendations on IT career development\",\n",
    "        \"Just got a new security analyst position, very excited!\"\n",
    "    ]\n",
    "    \n",
    "    predictions = predict_new_data(best_model, vectorizer, sample_texts)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"PIPELINE COMPLETED SUCCESSFULLY!\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"\\nNext steps:\")\n",
    "    print(\"1. Review the confusion matrix: confusion_matrix.png\")\n",
    "    print(\"2. Use the saved model for predictions: best_model.pkl\")\n",
    "    print(\"3. Consider collecting more data for underrepresented classes\")\n",
    "    print(\"4. Experiment with different preprocessing and feature extraction methods\")\n",
    "    print(\"5. Try deep learning models if you have more data\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
