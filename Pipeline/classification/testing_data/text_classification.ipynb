{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d72f764e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All necessary libraries imported successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, \n",
    "                             accuracy_score, f1_score, precision_score, recall_score)\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# For deep learning (optional - if you want to use neural networks)\n",
    "try:\n",
    "    from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "    from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import Dense, Embedding, LSTM, Dropout\n",
    "    KERAS_AVAILABLE = True\n",
    "except ImportError:\n",
    "    KERAS_AVAILABLE = False\n",
    "    print(\"TensorFlow/Keras not available. Will skip deep learning models.\")\n",
    "\n",
    "print(\"All necessary libraries imported successfully.\")\n",
    "\n",
    "\n",
    "#pip install tensorflow scikit-learn pandas numpy matplotlib seaborn openpyxl xlrd imbalanced-learn --break-system-packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc0df881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1: DATA LOADING & EXPLORATION\n",
    "# ============================================================================\n",
    "\n",
    "def load_and_explore_data(file_path):\n",
    "    \"\"\"Load data and perform initial exploration\"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    print(\"STEP 1: DATA LOADING & EXPLORATION\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Load data\n",
    "    df = pd.read_excel(file_path)\n",
    "    \n",
    "    print(f\"\\nDataset shape: {df.shape}\")\n",
    "    print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "    print(f\"\\nFirst few rows:\")\n",
    "    print(df.head())\n",
    "    \n",
    "    print(f\"\\nLabel distribution:\")\n",
    "    print(df['label'].value_counts())\n",
    "    \n",
    "    print(f\"\\nMissing values:\")\n",
    "    print(df.isnull().sum())\n",
    "    \n",
    "    print(f\"\\nText length statistics:\")\n",
    "    df['text_length'] = df['text'].apply(lambda x: len(str(x)))\n",
    "    print(df['text_length'].describe())\n",
    "    \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d9f199c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 2: DATA PREPROCESSING\n",
    "# ============================================================================\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Clean and preprocess text data\"\"\"\n",
    "    # Convert to lowercase\n",
    "    text = str(text).lower()\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www.\\S+', '', text)\n",
    "    \n",
    "    # Remove special characters and digits (optional - depending on your use case)\n",
    "    # text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    \n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "def handle_multilabels(df, strategy='first'):\n",
    "    \"\"\"\n",
    "    Handle multi-label samples\n",
    "    \n",
    "    Strategies:\n",
    "    - 'first': Take the first label\n",
    "    - 'remove': Remove multi-label samples\n",
    "    - 'separate': Create separate samples for each label (data augmentation)\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"STEP 3: HANDLING MULTI-LABELS\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Identify multi-label samples\n",
    "    multi_label_mask = df['label'].astype(str).str.contains(',')\n",
    "    multi_label_count = multi_label_mask.sum()\n",
    "    \n",
    "    print(f\"\\nMulti-label samples found: {multi_label_count}\")\n",
    "    print(f\"Multi-label samples: {df[multi_label_mask]['label'].unique()}\")\n",
    "    \n",
    "    if strategy == 'first':\n",
    "        print(\"\\nStrategy: Taking first label from multi-label samples\")\n",
    "        df['label'] = df['label'].astype(str).apply(lambda x: x.split(',')[0])\n",
    "        \n",
    "    elif strategy == 'remove':\n",
    "        print(\"\\nStrategy: Removing multi-label samples\")\n",
    "        df = df[~multi_label_mask].copy()\n",
    "        \n",
    "    elif strategy == 'separate':\n",
    "        print(\"\\nStrategy: Creating separate samples for each label\")\n",
    "        new_rows = []\n",
    "        for idx, row in df[multi_label_mask].iterrows():\n",
    "            labels = str(row['label']).split(',')\n",
    "            for label in labels:\n",
    "                new_row = row.copy()\n",
    "                new_row['label'] = label.strip()\n",
    "                new_rows.append(new_row)\n",
    "        \n",
    "        # Remove original multi-label rows and add new rows\n",
    "        df = pd.concat([df[~multi_label_mask], pd.DataFrame(new_rows)], ignore_index=True)\n",
    "    \n",
    "    # Convert labels to integers\n",
    "    df['label'] = df['label'].astype(int)\n",
    "    \n",
    "    print(f\"\\nFinal label distribution:\")\n",
    "    print(df['label'].value_counts().sort_index())\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "187b932c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 4: TRAIN-TEST SPLIT\n",
    "# ============================================================================\n",
    "\n",
    "def split_data(df, test_size=0.2, random_state=42, stratify=True):\n",
    "    \"\"\"Split data into train and test sets\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"STEP 4: TRAIN-TEST SPLIT\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    X = df['text'].values\n",
    "    y = df['label'].values\n",
    "    \n",
    "    # Use stratified split to maintain class distribution\n",
    "    if stratify:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=test_size, random_state=random_state, stratify=y\n",
    "        )\n",
    "    else:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=test_size, random_state=random_state\n",
    "        )\n",
    "    \n",
    "    print(f\"\\nTraining set size: {len(X_train)}\")\n",
    "    print(f\"Test set size: {len(X_test)}\")\n",
    "    print(f\"\\nTraining set label distribution:\")\n",
    "    print(pd.Series(y_train).value_counts().sort_index())\n",
    "    print(f\"\\nTest set label distribution:\")\n",
    "    print(pd.Series(y_test).value_counts().sort_index())\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a08914e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 5: FEATURE EXTRACTION\n",
    "# ============================================================================\n",
    "\n",
    "def extract_features_tfidf(X_train, X_test, max_features=1000):\n",
    "    \"\"\"Extract TF-IDF features\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"STEP 5: FEATURE EXTRACTION (TF-IDF)\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    vectorizer = TfidfVectorizer(\n",
    "        max_features=max_features,\n",
    "        min_df=2,  # Ignore terms that appear in less than 2 documents\n",
    "        max_df=0.8,  # Ignore terms that appear in more than 80% of documents\n",
    "        ngram_range=(1, 2),  # Use unigrams and bigrams\n",
    "        stop_words='english'\n",
    "    )\n",
    "    \n",
    "    X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "    X_test_tfidf = vectorizer.transform(X_test)\n",
    "    \n",
    "    print(f\"\\nTF-IDF matrix shape (train): {X_train_tfidf.shape}\")\n",
    "    print(f\"TF-IDF matrix shape (test): {X_test_tfidf.shape}\")\n",
    "    print(f\"Number of features: {len(vectorizer.get_feature_names_out())}\")\n",
    "    \n",
    "    return X_train_tfidf, X_test_tfidf, vectorizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "64758c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 6: MODEL TRAINING\n",
    "# ============================================================================\n",
    "\n",
    "def train_models(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"Train multiple models and compare performance\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"STEP 6: MODEL TRAINING\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    models = {\n",
    "        'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42, class_weight='balanced'),\n",
    "        'Naive Bayes': MultinomialNB(),\n",
    "        'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced'),\n",
    "        'SVM': SVC(kernel='linear', random_state=42, class_weight='balanced')\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        print(f\"\\n{'='*40}\")\n",
    "        print(f\"Training {name}...\")\n",
    "        print(f\"{'='*40}\")\n",
    "        \n",
    "        # Train\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Evaluate\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        f1_weighted = f1_score(y_test, y_pred, average='weighted')\n",
    "        f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "        \n",
    "        print(f\"\\nAccuracy: {accuracy:.4f}\")\n",
    "        print(f\"F1 Score (Weighted): {f1_weighted:.4f}\")\n",
    "        print(f\"F1 Score (Macro): {f1_macro:.4f}\")\n",
    "        \n",
    "        print(f\"\\nClassification Report:\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        \n",
    "        results[name] = {\n",
    "            'model': model,\n",
    "            'accuracy': accuracy,\n",
    "            'f1_weighted': f1_weighted,\n",
    "            'f1_macro': f1_macro,\n",
    "            'predictions': y_pred\n",
    "        }\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c38acad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 7: MODEL EVALUATION\n",
    "# ============================================================================\n",
    "\n",
    "def evaluate_best_model(results, y_test):\n",
    "    \"\"\"Evaluate and visualize the best model\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"STEP 7: MODEL EVALUATION\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Find best model based on F1 weighted score\n",
    "    best_model_name = max(results, key=lambda k: results[k]['f1_weighted'])\n",
    "    best_model = results[best_model_name]['model']\n",
    "    best_predictions = results[best_model_name]['predictions']\n",
    "    \n",
    "    print(f\"\\nBest Model: {best_model_name}\")\n",
    "    print(f\"Accuracy: {results[best_model_name]['accuracy']:.4f}\")\n",
    "    print(f\"F1 Score (Weighted): {results[best_model_name]['f1_weighted']:.4f}\")\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, best_predictions)\n",
    "    \n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(cm)\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f'Confusion Matrix - {best_model_name}')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.savefig('confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(\"\\nConfusion matrix saved to: confusion_matrix.png\")\n",
    "    \n",
    "    return best_model_name, best_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b2d74f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 8: HYPERPARAMETER TUNING\n",
    "# ============================================================================\n",
    "\n",
    "def tune_hyperparameters(X_train, y_train, model_type='logistic'):\n",
    "    \"\"\"Perform hyperparameter tuning\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"STEP 8: HYPERPARAMETER TUNING\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    if model_type == 'logistic':\n",
    "        model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "        param_grid = {\n",
    "            'C': [0.01, 0.1, 1, 10],\n",
    "            'penalty': ['l1', 'l2'],\n",
    "            'solver': ['liblinear', 'saga'],\n",
    "            'class_weight': ['balanced', None]\n",
    "        }\n",
    "    elif model_type == 'random_forest':\n",
    "        model = RandomForestClassifier(random_state=42)\n",
    "        param_grid = {\n",
    "            'n_estimators': [50, 100, 200],\n",
    "            'max_depth': [10, 20, None],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'class_weight': ['balanced', None]\n",
    "        }\n",
    "    else:\n",
    "        raise ValueError(\"model_type must be 'logistic' or 'random_forest'\")\n",
    "    \n",
    "    print(f\"\\nTuning {model_type} model...\")\n",
    "    print(f\"Parameter grid: {param_grid}\")\n",
    "    \n",
    "    grid_search = GridSearchCV(\n",
    "        model, \n",
    "        param_grid, \n",
    "        cv=5,  # 5-fold cross-validation\n",
    "        scoring='f1_weighted',\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    print(f\"\\nBest parameters: {grid_search.best_params_}\")\n",
    "    print(f\"Best cross-validation F1 score: {grid_search.best_score_:.4f}\")\n",
    "    \n",
    "    return grid_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6288b0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 9: MODEL SAVING\n",
    "# ============================================================================\n",
    "\n",
    "def save_model(model, vectorizer, filepath_model, filepath_vectorizer):\n",
    "    \"\"\"Save trained model and vectorizer\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"STEP 9: SAVING MODEL\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    import pickle\n",
    "    \n",
    "    # Save model\n",
    "    with open(filepath_model, 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "    print(f\"\\nModel saved to: {filepath_model}\")\n",
    "    \n",
    "    # Save vectorizer\n",
    "    with open(filepath_vectorizer, 'wb') as f:\n",
    "        pickle.dump(vectorizer, f)\n",
    "    print(f\"Vectorizer saved to: {filepath_vectorizer}\")\n",
    "\n",
    "\n",
    "def load_model(filepath_model, filepath_vectorizer):\n",
    "    \"\"\"Load saved model and vectorizer\"\"\"\n",
    "    import pickle\n",
    "    \n",
    "    with open(filepath_model, 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "    \n",
    "    with open(filepath_vectorizer, 'rb') as f:\n",
    "        vectorizer = pickle.load(f)\n",
    "    \n",
    "    return model, vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7a054401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 10: PREDICTION ON NEW DATA\n",
    "# ============================================================================\n",
    "\n",
    "def predict_new_data(model, vectorizer, new_texts):\n",
    "    \"\"\"Predict labels for new text data\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"STEP 10: PREDICTION ON NEW DATA\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Preprocess\n",
    "    new_texts_processed = [preprocess_text(text) for text in new_texts]\n",
    "    \n",
    "    # Vectorize\n",
    "    new_texts_tfidf = vectorizer.transform(new_texts_processed)\n",
    "    \n",
    "    # Predict\n",
    "    predictions = model.predict(new_texts_tfidf)\n",
    "    \n",
    "    # Get prediction probabilities (if available)\n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        probabilities = model.predict_proba(new_texts_tfidf)\n",
    "        \n",
    "        for i, (text, pred, prob) in enumerate(zip(new_texts, predictions, probabilities)):\n",
    "            print(f\"\\nText {i+1}: {text[:100]}...\")\n",
    "            print(f\"Predicted Label: {pred}\")\n",
    "            print(f\"Confidence: {max(prob):.4f}\")\n",
    "    else:\n",
    "        for i, (text, pred) in enumerate(zip(new_texts, predictions)):\n",
    "            print(f\"\\nText {i+1}: {text[:100]}...\")\n",
    "            print(f\"Predicted Label: {pred}\")\n",
    "    \n",
    "    return predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f36754b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TEXT CLASSIFICATION MODEL TRAINING PIPELINE\n",
      "================================================================================\n",
      "================================================================================\n",
      "STEP 1: DATA LOADING & EXPLORATION\n",
      "================================================================================\n",
      "\n",
      "Dataset shape: (177, 4)\n",
      "\n",
      "Columns: ['id', 'text', 'similarity_score', 'label']\n",
      "\n",
      "First few rows:\n",
      "        id                                               text  \\\n",
      "0  1g4a7ot  Burn out among Cybersecurity leaders at a frus...   \n",
      "1  1dqiog2  Invitation to Participate in Research Study on...   \n",
      "2  1g49xt4  Dealing with feeling stuck in the security fie...   \n",
      "3  1fqxn7a  How are you doing guys?\\nIs this cybersecurity...   \n",
      "4  1fbdhwo  Hey folks, for those of you working right now,...   \n",
      "\n",
      "   similarity_score label  \n",
      "0          0.437536     1  \n",
      "1          0.400815     0  \n",
      "2          0.281245     0  \n",
      "3          0.316323     1  \n",
      "4          0.377892     2  \n",
      "\n",
      "Label distribution:\n",
      "label\n",
      "0      107\n",
      "1       38\n",
      "2        8\n",
      "6        6\n",
      "3        3\n",
      "9        3\n",
      "7        3\n",
      "5        2\n",
      "7,8      2\n",
      "4        2\n",
      "4,8      1\n",
      "2,9      1\n",
      "1,4      1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Missing values:\n",
      "id                  0\n",
      "text                0\n",
      "similarity_score    0\n",
      "label               0\n",
      "dtype: int64\n",
      "\n",
      "Text length statistics:\n",
      "count     177.000000\n",
      "mean      627.129944\n",
      "std      1004.791515\n",
      "min        11.000000\n",
      "25%        88.000000\n",
      "50%       303.000000\n",
      "75%       727.000000\n",
      "max      9549.000000\n",
      "Name: text_length, dtype: float64\n",
      "\n",
      "================================================================================\n",
      "STEP 2: TEXT PREPROCESSING\n",
      "================================================================================\n",
      "\n",
      "Sample preprocessed text:\n",
      "burn out among cybersecurity leaders at a frustrating high. in a world of high powered ai and evolving threat actors; cyber security leaders are facing significant amounts of burnout and stress. anyone experienced this as well? [\n",
      "\n",
      "================================================================================\n",
      "STEP 3: HANDLING MULTI-LABELS\n",
      "================================================================================\n",
      "\n",
      "Multi-label samples found: 5\n",
      "Multi-label samples: ['7,8' '4,8' '2,9' '1,4']\n",
      "\n",
      "Strategy: Taking first label from multi-label samples\n",
      "\n",
      "Final label distribution:\n",
      "label\n",
      "0    107\n",
      "1     39\n",
      "2      9\n",
      "3      3\n",
      "4      3\n",
      "5      2\n",
      "6      6\n",
      "7      5\n",
      "9      3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "================================================================================\n",
      "STEP 4: TRAIN-TEST SPLIT\n",
      "================================================================================\n",
      "\n",
      "Training set size: 141\n",
      "Test set size: 36\n",
      "\n",
      "Training set label distribution:\n",
      "0    85\n",
      "1    31\n",
      "2     7\n",
      "3     3\n",
      "4     2\n",
      "5     2\n",
      "6     5\n",
      "7     4\n",
      "9     2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test set label distribution:\n",
      "0    22\n",
      "1     8\n",
      "2     2\n",
      "4     1\n",
      "6     1\n",
      "7     1\n",
      "9     1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "================================================================================\n",
      "STEP 5: FEATURE EXTRACTION (TF-IDF)\n",
      "================================================================================\n",
      "\n",
      "TF-IDF matrix shape (train): (141, 500)\n",
      "TF-IDF matrix shape (test): (36, 500)\n",
      "Number of features: 500\n",
      "\n",
      "================================================================================\n",
      "STEP 6: MODEL TRAINING\n",
      "================================================================================\n",
      "\n",
      "========================================\n",
      "Training Logistic Regression...\n",
      "========================================\n",
      "\n",
      "Accuracy: 0.6667\n",
      "F1 Score (Weighted): 0.6695\n",
      "F1 Score (Macro): 0.4827\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.77      0.79        22\n",
      "           1       0.56      0.62      0.59         8\n",
      "           2       0.00      0.00      0.00         2\n",
      "           4       1.00      1.00      1.00         1\n",
      "           6       1.00      1.00      1.00         1\n",
      "           7       0.00      0.00      0.00         1\n",
      "           9       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.67        36\n",
      "   macro avg       0.48      0.49      0.48        36\n",
      "weighted avg       0.67      0.67      0.67        36\n",
      "\n",
      "\n",
      "========================================\n",
      "Training Naive Bayes...\n",
      "========================================\n",
      "\n",
      "Accuracy: 0.6111\n",
      "F1 Score (Weighted): 0.4636\n",
      "F1 Score (Macro): 0.1084\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      1.00      0.76        22\n",
      "           1       0.00      0.00      0.00         8\n",
      "           2       0.00      0.00      0.00         2\n",
      "           4       0.00      0.00      0.00         1\n",
      "           6       0.00      0.00      0.00         1\n",
      "           7       0.00      0.00      0.00         1\n",
      "           9       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.61        36\n",
      "   macro avg       0.09      0.14      0.11        36\n",
      "weighted avg       0.37      0.61      0.46        36\n",
      "\n",
      "\n",
      "========================================\n",
      "Training Random Forest...\n",
      "========================================\n",
      "\n",
      "Accuracy: 0.6944\n",
      "F1 Score (Weighted): 0.6065\n",
      "F1 Score (Macro): 0.3112\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      1.00      0.81        22\n",
      "           1       0.67      0.25      0.36         8\n",
      "           2       0.00      0.00      0.00         2\n",
      "           4       0.00      0.00      0.00         1\n",
      "           6       1.00      1.00      1.00         1\n",
      "           7       0.00      0.00      0.00         1\n",
      "           9       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.69        36\n",
      "   macro avg       0.34      0.32      0.31        36\n",
      "weighted avg       0.60      0.69      0.61        36\n",
      "\n",
      "\n",
      "========================================\n",
      "Training SVM...\n",
      "========================================\n",
      "\n",
      "Accuracy: 0.6667\n",
      "F1 Score (Weighted): 0.6447\n",
      "F1 Score (Macro): 0.3349\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82        22\n",
      "           1       0.45      0.62      0.53         8\n",
      "           2       0.00      0.00      0.00         2\n",
      "           4       0.00      0.00      0.00         1\n",
      "           6       1.00      1.00      1.00         1\n",
      "           7       0.00      0.00      0.00         1\n",
      "           9       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.67        36\n",
      "   macro avg       0.32      0.35      0.33        36\n",
      "weighted avg       0.63      0.67      0.64        36\n",
      "\n",
      "\n",
      "================================================================================\n",
      "STEP 7: MODEL EVALUATION\n",
      "================================================================================\n",
      "\n",
      "Best Model: Logistic Regression\n",
      "Accuracy: 0.6667\n",
      "F1 Score (Weighted): 0.6695\n",
      "\n",
      "Confusion Matrix:\n",
      "[[17  1  4  0  0  0  0]\n",
      " [ 3  5  0  0  0  0  0]\n",
      " [ 1  1  0  0  0  0  0]\n",
      " [ 0  0  0  1  0  0  0]\n",
      " [ 0  0  0  0  1  0  0]\n",
      " [ 0  1  0  0  0  0  0]\n",
      " [ 0  1  0  0  0  0  0]]\n",
      "\n",
      "Confusion matrix saved to: confusion_matrix.png\n",
      "\n",
      "Would you like to perform hyperparameter tuning? (Recommended for better results)\n",
      "Skipping for now - you can uncomment the lines below to enable it\n",
      "\n",
      "================================================================================\n",
      "STEP 9: SAVING MODEL\n",
      "================================================================================\n",
      "\n",
      "Model saved to: best_model.pkl\n",
      "Vectorizer saved to: vectorizer.pkl\n",
      "\n",
      "================================================================================\n",
      "STEP 10: PREDICTION ON NEW DATA\n",
      "================================================================================\n",
      "\n",
      "Text 1: I'm experiencing severe burnout in my cybersecurity role...\n",
      "Predicted Label: 1\n",
      "Confidence: 0.2744\n",
      "\n",
      "Text 2: Looking for recommendations on IT career development...\n",
      "Predicted Label: 0\n",
      "Confidence: 0.2348\n",
      "\n",
      "Text 3: Just got a new security analyst position, very excited!...\n",
      "Predicted Label: 0\n",
      "Confidence: 0.1597\n",
      "\n",
      "================================================================================\n",
      "PIPELINE COMPLETED SUCCESSFULLY!\n",
      "================================================================================\n",
      "\n",
      "Next steps:\n",
      "1. Review the confusion matrix: confusion_matrix.png\n",
      "2. Use the saved model for predictions: best_model.pkl\n",
      "3. Consider collecting more data for underrepresented classes\n",
      "4. Experiment with different preprocessing and feature extraction methods\n",
      "5. Try deep learning models if you have more data\n"
     ]
    }
   ],
   "source": [
    "# MAIN PIPELINE\n",
    "# ============================================================================\n",
    "\n",
    "def main():\n",
    "    \"\"\"Run the complete classification pipeline\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"TEXT CLASSIFICATION MODEL TRAINING PIPELINE\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # File path\n",
    "    data_path = 'manual_label_batch1.xlsx'\n",
    "    \n",
    "    # Step 1: Load data\n",
    "    df = load_and_explore_data(data_path)\n",
    "    \n",
    "    # Step 2: Preprocess text\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"STEP 2: TEXT PREPROCESSING\")\n",
    "    print(\"=\" * 80)\n",
    "    df['text_processed'] = df['text'].apply(preprocess_text)\n",
    "    print(\"\\nSample preprocessed text:\")\n",
    "    print(df['text_processed'].iloc[0])\n",
    "    \n",
    "    # Step 3: Handle multi-labels\n",
    "    df = handle_multilabels(df, strategy='first')  # Change strategy as needed\n",
    "    \n",
    "    # Step 4: Split data\n",
    "    X_train, X_test, y_train, y_test = split_data(df, test_size=0.2)\n",
    "    \n",
    "    # Preprocess train and test texts\n",
    "    X_train_processed = [preprocess_text(text) for text in X_train]\n",
    "    X_test_processed = [preprocess_text(text) for text in X_test]\n",
    "    \n",
    "    # Step 5: Feature extraction\n",
    "    X_train_tfidf, X_test_tfidf, vectorizer = extract_features_tfidf(\n",
    "        X_train_processed, X_test_processed, max_features=500\n",
    "    )\n",
    "    \n",
    "    # Step 6: Train models\n",
    "    results = train_models(X_train_tfidf, y_train, X_test_tfidf, y_test)\n",
    "    \n",
    "    # Step 7: Evaluate best model\n",
    "    best_model_name, best_model = evaluate_best_model(results, y_test)\n",
    "    \n",
    "    # Step 8: Hyperparameter tuning (optional - can be slow)\n",
    "    print(\"\\nWould you like to perform hyperparameter tuning? (Recommended for better results)\")\n",
    "    print(\"Skipping for now - you can uncomment the lines below to enable it\")\n",
    "    # tuned_model = tune_hyperparameters(X_train_tfidf, y_train, model_type='logistic')\n",
    "    # y_pred_tuned = tuned_model.predict(X_test_tfidf)\n",
    "    # print(\"\\nTuned Model Results:\")\n",
    "    # print(classification_report(y_test, y_pred_tuned))\n",
    "    \n",
    "    # Step 9: Save model\n",
    "    save_model(\n",
    "        best_model, \n",
    "        vectorizer, \n",
    "        'best_model.pkl',\n",
    "        'vectorizer.pkl'\n",
    "    )\n",
    "    \n",
    "    # Step 10: Test prediction on new data\n",
    "    sample_texts = [\n",
    "        \"I'm experiencing severe burnout in my cybersecurity role\",\n",
    "        \"Looking for recommendations on IT career development\",\n",
    "        \"Just got a new security analyst position, very excited!\"\n",
    "    ]\n",
    "    \n",
    "    predictions = predict_new_data(best_model, vectorizer, sample_texts)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"PIPELINE COMPLETED SUCCESSFULLY!\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"\\nNext steps:\")\n",
    "    print(\"1. Review the confusion matrix: confusion_matrix.png\")\n",
    "    print(\"2. Use the saved model for predictions: best_model.pkl\")\n",
    "    print(\"3. Consider collecting more data for underrepresented classes\")\n",
    "    print(\"4. Experiment with different preprocessing and feature extraction methods\")\n",
    "    print(\"5. Try deep learning models if you have more data\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
